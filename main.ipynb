{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "light-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import nni\n",
    "import torch.nn.functional as F\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "# import ray\n",
    "# from ray import tune # for trialing\n",
    "# from ray.tune import JupyterNotebookReporter # for trial reporting\n",
    "# # from ray.tune.integration.torch import is_distributed_trainable\n",
    "# # from torch.nn.parallel import DistributedDataParallel\n",
    "# # from ray.tune.integration.torch import DistributedTrainableCreator\n",
    "# # from ray.tune.integration.torch import distributed_checkpoint_dir\n",
    "# from ray.tune.schedulers import ASHAScheduler # for trial scheduling\n",
    "# from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "# from ray.tune.suggest.bayesopt import BayesOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriental-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import Kaggle data\n",
    "# import kaggle\n",
    "# kagggle competitions download tabular-playground-series-mar-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "democratic-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to memory for discovery\n",
    "train,test = pd.read_csv('./train.csv',index_col=\"id\"),pd.read_csv('./test.csv',index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "standing-forest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 0 to 499999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   cat0    300000 non-null  object \n",
      " 1   cat1    300000 non-null  object \n",
      " 2   cat2    300000 non-null  object \n",
      " 3   cat3    300000 non-null  object \n",
      " 4   cat4    300000 non-null  object \n",
      " 5   cat5    300000 non-null  object \n",
      " 6   cat6    300000 non-null  object \n",
      " 7   cat7    300000 non-null  object \n",
      " 8   cat8    300000 non-null  object \n",
      " 9   cat9    300000 non-null  object \n",
      " 10  cat10   300000 non-null  object \n",
      " 11  cat11   300000 non-null  object \n",
      " 12  cat12   300000 non-null  object \n",
      " 13  cat13   300000 non-null  object \n",
      " 14  cat14   300000 non-null  object \n",
      " 15  cat15   300000 non-null  object \n",
      " 16  cat16   300000 non-null  object \n",
      " 17  cat17   300000 non-null  object \n",
      " 18  cat18   300000 non-null  object \n",
      " 19  cont0   300000 non-null  float64\n",
      " 20  cont1   300000 non-null  float64\n",
      " 21  cont2   300000 non-null  float64\n",
      " 22  cont3   300000 non-null  float64\n",
      " 23  cont4   300000 non-null  float64\n",
      " 24  cont5   300000 non-null  float64\n",
      " 25  cont6   300000 non-null  float64\n",
      " 26  cont7   300000 non-null  float64\n",
      " 27  cont8   300000 non-null  float64\n",
      " 28  cont9   300000 non-null  float64\n",
      " 29  cont10  300000 non-null  float64\n",
      " 30  target  300000 non-null  int64  \n",
      "dtypes: float64(11), int64(1), object(19)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get data structure\n",
    "train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "weird-month",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>Q</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759439</td>\n",
       "      <td>0.795549</td>\n",
       "      <td>0.681917</td>\n",
       "      <td>0.621672</td>\n",
       "      <td>0.592184</td>\n",
       "      <td>0.791921</td>\n",
       "      <td>0.815254</td>\n",
       "      <td>0.965006</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>K</td>\n",
       "      <td>W</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386385</td>\n",
       "      <td>0.541366</td>\n",
       "      <td>0.388982</td>\n",
       "      <td>0.357778</td>\n",
       "      <td>0.600044</td>\n",
       "      <td>0.408701</td>\n",
       "      <td>0.399353</td>\n",
       "      <td>0.927406</td>\n",
       "      <td>0.493729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BM</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343255</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.793687</td>\n",
       "      <td>0.552877</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.388835</td>\n",
       "      <td>0.412303</td>\n",
       "      <td>0.292696</td>\n",
       "      <td>0.549452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831147</td>\n",
       "      <td>0.807807</td>\n",
       "      <td>0.800032</td>\n",
       "      <td>0.619147</td>\n",
       "      <td>0.221789</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.633669</td>\n",
       "      <td>0.760318</td>\n",
       "      <td>0.934242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338818</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.610578</td>\n",
       "      <td>0.128291</td>\n",
       "      <td>0.578764</td>\n",
       "      <td>0.279167</td>\n",
       "      <td>0.351103</td>\n",
       "      <td>0.357084</td>\n",
       "      <td>0.328960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont2     cont3  \\\n",
       "id                                                    ...                       \n",
       "0     A    I    A    B    B   BI    A    S    Q    A  ...  0.759439  0.795549   \n",
       "1     A    I    A    A    E   BI    K    W   AD    F  ...  0.386385  0.541366   \n",
       "2     A    K    A    A    E   BI    A    E   BM    L  ...  0.343255  0.616352   \n",
       "3     A    K    A    C    E   BI    A    Y   AD    F  ...  0.831147  0.807807   \n",
       "4     A    I    G    B    E   BI    C    G    Q    A  ...  0.338818  0.277308   \n",
       "\n",
       "       cont4     cont5     cont6     cont7     cont8     cont9    cont10  \\\n",
       "id                                                                         \n",
       "0   0.681917  0.621672  0.592184  0.791921  0.815254  0.965006  0.665915   \n",
       "1   0.388982  0.357778  0.600044  0.408701  0.399353  0.927406  0.493729   \n",
       "2   0.793687  0.552877  0.352113  0.388835  0.412303  0.292696  0.549452   \n",
       "3   0.800032  0.619147  0.221789  0.897617  0.633669  0.760318  0.934242   \n",
       "4   0.610578  0.128291  0.578764  0.279167  0.351103  0.357084  0.328960   \n",
       "\n",
       "    target  \n",
       "id          \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at data examples\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nuclear-sandwich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categroy with median total unique values:\n",
      " cat3 :  13 unique values\n"
     ]
    }
   ],
   "source": [
    "# Get number of unique categories\n",
    "cal_cols = train.select_dtypes('object')\n",
    "cal_cols_keys = cal_cols.keys()\n",
    "# cal_cols_vals = np.array((cal_cols.values))\n",
    "\n",
    "#Build sample item\n",
    "cat_stats = np.array([train[c].nunique() for c in cal_cols])\n",
    "median_cat = math.ceil(np.median(cat_stats))\n",
    "target_cat_index = int(np.where(cat_stats == median_cat)[0])\n",
    "target_cat_name = cal_cols_keys[target_cat_index]\n",
    "\n",
    "print(\"Categroy with median total unique values:\\n\",target_cat_name,\": \",train[target_cat_name].nunique(),\"unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chronic-identifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat3 indices:\n",
      " {'B': 0, 'A': 1, 'C': 2, 'D': 3, 'G': 4, 'N': 5, 'H': 6, 'F': 7, 'E': 8, 'K': 9, 'I': 10, 'J': 11, 'L': 12}\n"
     ]
    }
   ],
   "source": [
    "# Index categories\n",
    "categoricals_to_ix = {}\n",
    "\n",
    "for c in train.select_dtypes('object'):\n",
    "    categoricals_to_ix[c] = {cat:i for i,cat in enumerate(train[c].unique())}\n",
    "\n",
    "#Confirm with sample indexing\n",
    "sample_cat = categoricals_to_ix[target_cat_name]\n",
    "print(target_cat_name,\"indices:\\n\",sample_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "married-relevance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanple cat3 category:\n",
      " H\n",
      "Sanple category embedding:\n",
      " tensor([[-0.3307,  0.5979,  0.5125]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Test embeddings\n",
    "test_embeds = {}\n",
    "\n",
    "for cix_key in categoricals_to_ix.keys():\n",
    "    cix = categoricals_to_ix[cix_key]\n",
    "    bag_size = len(cix)\n",
    "    embed_size = math.isqrt(bag_size) #hyperparameter to optimize later\n",
    "    test_embeds[cix_key] = nn.Embedding(bag_size,embed_size)\n",
    "\n",
    "#Confirm with sample embedding\n",
    "target_cat_keys = list(sample_cat.keys())\n",
    "target_cat_vals = np.array(list(sample_cat.values()))\n",
    "target_cat_vals_median = math.ceil(np.median(target_cat_vals))\n",
    "target_cat_keys_sample = target_cat_keys[target_cat_vals_median]\n",
    "print(\"Sanple\",target_cat_name,\"category:\\n\",target_cat_keys_sample)\n",
    "    \n",
    "testor = torch.tensor([categoricals_to_ix[target_cat_name][target_cat_keys_sample]], dtype=torch.long)\n",
    "cat_keys_sample_hash = test_embeds[target_cat_name](testor)\n",
    "print(\"Sanple category embedding:\\n\",cat_keys_sample_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "periodic-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embeddings content (dictionary and translations)\n",
    "#function to build embeddings library\n",
    "#function assumes only categorical features are fed in\n",
    "def BuildEmbedlibrary(features):\n",
    "    categoricals_to_ix,embeds = {},{}\n",
    "    \n",
    "    #Build category index\n",
    "    for c in features:\n",
    "        categoricals_to_ix[c] = {cat:i for i,cat in enumerate(train[c].unique())}\n",
    "    \n",
    "    #Create embeddings for each feature\n",
    "    for cix_key in categoricals_to_ix.keys():\n",
    "        cix = categoricals_to_ix[cix_key]\n",
    "        bag_size = len(cix)\n",
    "        embed_size = math.isqrt(bag_size) #hyperparameter to optimize later\n",
    "        embeds[cix_key] = nn.Embedding(bag_size,embed_size)\n",
    "    \n",
    "#         print(embeds[cix_key])\n",
    "    return categoricals_to_ix,embeds\n",
    "\n",
    "#function that gets respective embedding for given feature value\n",
    "def CatToSubvector(category,feature_name,categorical_library,embedding_library,verbose=False):\n",
    "    if verbose:\n",
    "#         print(verbose)\n",
    "#         for info in [categorical_library]:\n",
    "# #         for info in [category,feature_name,categorical_library,embedding_library]:\n",
    "#             print(info,\"\\n\")\n",
    "        print(\"category: {}; feature_name: {}; categorical_library: {}; embedding_library: {}\".format(\n",
    "            category,\n",
    "            feature_name,\n",
    "            categorical_library,\n",
    "            embedding_library\n",
    "        ))\n",
    "#     [print(valu,\"\\n\") for valu in [category,feature_name,categorical_library,embedding_library]]\n",
    "    raw_idx = torch.tensor([categorical_library[feature_name][category]], dtype=torch.long)\n",
    "#     if (verbose): print(\"embedding_library[feature_name]:\",embedding_library[feature_name],\"\\n\",\"raw_idx:\",raw_idx)\n",
    "    emb = embedding_library[feature_name](raw_idx)\n",
    "#     if (verbose): print(\"embedding_library[feature_name](raw_idx):\",emb,\"\\n\")\n",
    "#     subvector = torch.Tensor(emb)\n",
    "#     if (verbose): print(\"subvector:\",subvector)\n",
    "    \n",
    "#     return subvector\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quiet-tennis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Test:\n",
      "\tSanple feature: cat3\n",
      "\tSanple category: H\n",
      "\tSanple category embedding: tensor([[0.0620, 0.9258, 0.0037]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# # Confirm function structure\n",
    "test_cat_dict,test_embeddings = BuildEmbedlibrary(train.select_dtypes('object'))\n",
    "test_subvec = CatToSubvector(target_cat_keys_sample,target_cat_name,test_cat_dict,test_embeddings)\n",
    "\n",
    "print(\"Embedding Test:\")\n",
    "print(\"\\tSanple feature:\",target_cat_name)\n",
    "print(\"\\tSanple category:\",target_cat_keys_sample)\n",
    "print(\"\\tSanple category embedding:\",test_subvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consolidated-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data\n",
    "\n",
    "#define dataset\n",
    "class ClaimsDataset(Dataset):\n",
    "    def __init__(self, csv_path,labelled=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            raw_data (dataframe): Dataframe with raw featurres and labels.\n",
    "        \"\"\"\n",
    "        file_check_target = \"train\" if (labelled) else \"test\"\n",
    "        \n",
    "#         print(\"{}_set_x.pt\".format(file_check_target))\n",
    "#         print(\"{}_set_y.pt\".format(file_check_target))\n",
    "        \n",
    "        if(exists( \"{}_set_x.pt\".format(file_check_target) ) and exists( \"{}_set_y.pt\".format(file_check_target) )):\n",
    "            self.data = torch.load(\"{}_set_x.pt\".format(file_check_target))\n",
    "            self.target = torch.load(\"{}_set_y.pt\".format(file_check_target))\n",
    "        else:\n",
    "            # Read data\n",
    "            raw_data = pd.read_csv(csv_path)\n",
    "\n",
    "    #         self.l = len(raw_data)\n",
    "            # Separate future parameters/labels\n",
    "            labels = raw_data.pop('target') if labelled else torch.tensor([], dtype=torch.long)\n",
    "            categorical_features = raw_data.select_dtypes(include='object')\n",
    "            noncategorical_features = raw_data.select_dtypes(exclude='object')\n",
    "\n",
    "            # Build feature embeddings\n",
    "            categoricals,embeddings = BuildEmbedlibrary(categorical_features)\n",
    "\n",
    "            # Convert embeddings to parameters\n",
    "            subvects = DataFrame()\n",
    "    #         for row in categorical_features.values:\n",
    "    #             subsubvects = []\n",
    "    #             for v,c in zip(row,categorical_features.columns):\n",
    "    #                 subsubvects.append(CatToSubvector(v,c,self.categoricals,self.embeddings))\n",
    "    # #             [print(\"subsubvect size:\",ssv.size()) for ssv in subsubvects]\n",
    "    #             subvects.append(torch.cat(subsubvects,1))\n",
    "            subsubvects = []\n",
    "\n",
    "            for col in categorical_features.columns:\n",
    "                print(\"Converting collection of categories, {}, to collection of embeddings...\".format(col))\n",
    "                cat_col = (categorical_features[col]).tolist()\n",
    "    #             print(\"cat_col:\",cat_col,\"\\n\")\n",
    "    #             cat_emb = cat_col\n",
    "    #             cat_emb = cat_col.apply(lambda x: CatToSubvector(x,col,self.categoricals,self.embeddings,True))\n",
    "    #             if (i%2):# == 0 and i!=0):\n",
    "    #                 print(\"i:\",i)\n",
    "    #                 cat_emb = cat_col.apply(lambda x: CatToSubvector(x,col,self.categoricals,self.embeddings,True))\n",
    "    #                 print(\"cat_emb:\",cat_emb,\"\\n\")\n",
    "    #             else:\n",
    "    #                 cat_emb = cat_col.apply(lambda x: CatToSubvector(x,col,self.categoricals,self.embeddings,False))\n",
    "                cat_embs = CatToSubvector(cat_col[0],col,categoricals,embeddings,False)\n",
    "                for x in cat_col[1:]:\n",
    "                    new_emb = CatToSubvector(x,col,categoricals,embeddings,False)\n",
    "                    cat_embs = torch.cat((cat_embs,new_emb))\n",
    "    #             cat_emb = [CatToSubvector(x,col,self.categoricals,self.embeddings) for x in cat_col]\n",
    "    #             print(col,\"cat_embs.shape:\",cat_embs.shape,\"\\n\")\n",
    "    #             cat_emb = torch.cat(tuple(cat_emb))\n",
    "    #             print(\"type(cat_emb[-10]):\",type(cat_emb[-10]),\"\\n\")\n",
    "    #             print(\"cat_emb[-10]:\",cat_emb[-10],\"\\n\")\n",
    "                subsubvects.append(cat_embs)\n",
    "\n",
    "    #         print(\"tuple(subsubvects):\",tuple(subsubvects),\"\\n\")\n",
    "            subvects = torch.cat(tuple(subsubvects),1)\n",
    "    #         print(\"subvects[1]:\",subvects[1],\"\\n\")\n",
    "    #         print(\"subvects.shape:\",subvects.shape,\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            # copy the data \n",
    "            df_min_max_scaled = noncategorical_features.copy()\n",
    "\n",
    "            # apply normalization techniques by Column 1 \n",
    "            for col in df_min_max_scaled.columns:\n",
    "                df_min_max_scaled[col] = (df_min_max_scaled[col] - df_min_max_scaled[col].min()) /\\\n",
    "                    (df_min_max_scaled[col].max() - df_min_max_scaled[col].min())\n",
    "\n",
    "    #         noncat_mean = noncategorical_features.mean(1)\n",
    "    #         noncat_std = noncategorical_features.std(1)\n",
    "\n",
    "\n",
    "            self.data = torch.cat((\n",
    "                subvects,\n",
    "    #             torch.tensor(noncategorical_features.values)\n",
    "                torch.tensor(df_min_max_scaled.values)\n",
    "            ),1)\n",
    "            torch.save(self.data,\"{}_set_x.pt\".format(file_check_target))\n",
    "\n",
    "    #         print(\"labels:\",labels)\n",
    "    #         print(\"labels.tolist():\",labels.tolist())\n",
    "            self.target = torch.tensor(labels.tolist(), dtype=torch.int)\n",
    "            torch.save(self.target,\"{}_set_y.pt\".format(file_check_target))\n",
    "    #         print(\"self.target:\",self.target)\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "            \n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boolean-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO add functionality for unlabbeled data\n",
    "def LoadData(bs=4,target='train'):\n",
    "    sets = {\n",
    "        'train':None,\n",
    "        'test':None,\n",
    "    }\n",
    "    train_loader,test_loader = None,None\n",
    "#     bs = 2*batch_size_oom\n",
    "    \n",
    "    if(target=='train'):\n",
    "        sets['train'] = ClaimsDataset('./train.csv',labelled=True)\n",
    "        train_loader = DataLoader(sets['train'],batch_size=bs,shuffle=True)\n",
    "    elif(target=='test'):\n",
    "        sets['test'] = ClaimsDataset('./test.csv')\n",
    "        test_loader = DataLoader(sets['test'],batch_size=bs,shuffle=True)\n",
    "    elif(target=='both'):\n",
    "        sets['train'],sets['test'] = ClaimsDataset('./train.csv',labelled=True),ClaimsDataset('./test.csv')\n",
    "        train_loader,test_loader = DataLoader(sets['train'],batch_size=bs,shuffle=True),DataLoader(sets['test'],batch_size=bs,shuffle=True)\n",
    "    else:\n",
    "        print(\"Invalid target name supplied. Returning None.\")\n",
    "    \n",
    "#     train_set,test_set = ClaimsDataset('./train.csv',labelled=True),ClaimsDataset('./test.csv')\n",
    "#     train_loader,test_loader = DataLoader(claimset,batch_size=bs,shuffle=True)\n",
    "#     train_loader,test_loader = DataLoader(train_set,batch_size=bs,shuffle=True),DataLoader(test_set,batch_size=bs,shuffle=True)\n",
    "    \n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "civic-lesbian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "x: tensor([[-0.6965, -0.2979,  0.4077, -0.6213, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.8375,  0.0085,  0.2313, -0.6016, -0.2974,  1.8078,  1.0748, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653,  0.5138,  0.3910,  0.3856,  1.0835,\n",
      "         -0.0882,  0.1051,  1.2432,  0.2977,  0.6710, -0.8622,  2.5038,  0.4307,\n",
      "         -1.2018, -0.8268, -0.3651,  0.2640,  1.1973,  0.2725, -0.1083, -0.0272,\n",
      "          0.1926, -2.5174, -0.2493,  0.7241,  0.1441, -1.6702,  0.1370,  0.2136,\n",
      "         -1.3672,  1.0691,  0.8435, -1.5849, -1.0602,  0.6213, -0.0863,  0.1523,\n",
      "         -0.3435, -0.6364,  1.2252,  0.0473,  0.7524,  0.3026, -1.2232,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.6810,  0.6258,  0.7782,  0.7351,  0.8221,\n",
      "          0.7600,  0.1263,  0.3402,  0.8293,  0.7478,  0.9246,  0.6246],\n",
      "        [ 0.2649, -0.5148, -1.7510, -0.1913, -0.5488,  1.3885,  0.6922,  0.3423,\n",
      "          0.7208, -0.0920, -0.8047, -0.6669,  0.0536,  0.3133,  1.0023,  2.5716,\n",
      "          0.6523, -0.1905, -0.5340, -1.2295,  1.6530,  1.3033, -0.9646, -1.4434,\n",
      "         -0.6992, -0.1991,  0.8427,  0.4096, -0.1811,  0.8460,  1.0334,  0.0071,\n",
      "          2.4760,  0.3610,  0.5643, -0.3696,  0.8920, -0.9489, -0.9740,  0.4667,\n",
      "          1.7849,  1.0409,  2.5867,  0.7567, -1.1740, -0.8622, -0.0269, -1.3850,\n",
      "          0.7297,  0.1987, -0.0877,  0.6307, -0.1725,  0.3917, -1.6876,  1.0670,\n",
      "          0.6703, -0.0312, -0.0862,  0.8054, -0.6882,  0.3120,  0.3955,  0.1523,\n",
      "         -1.2131, -0.6364,  0.9847,  0.0473,  0.7524,  0.3026, -1.2232,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.1246,  0.2103,  0.1654,  0.1479,  0.3528,\n",
      "          0.9549,  0.1047,  0.3338,  0.1974,  0.2960,  0.6200,  0.2626],\n",
      "        [ 0.2649,  0.4397, -0.1099, -0.5398, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.5506,  0.9355,  1.2027, -0.0244,  1.0849,  1.1587,  0.2736, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653,  2.4896,  0.0176,  0.0684,  0.1907,\n",
      "         -0.3394, -1.0779,  0.3261, -0.5690, -0.8721, -0.0805, -0.0758,  0.2283,\n",
      "          0.1060,  1.7873, -0.3651,  0.2640,  1.1973,  0.2725, -0.4299,  0.2179,\n",
      "         -1.1328,  1.8029, -0.9319,  0.1202, -0.8447,  0.4762,  0.2760, -0.3521,\n",
      "         -0.1286,  1.3973, -0.1903,  1.2719,  1.0437,  0.0038, -2.0258,  0.1523,\n",
      "         -0.3435, -0.6364,  0.9847,  0.0473,  0.7524,  0.3026, -1.2232, -2.2034,\n",
      "          1.5220, -1.8895,  1.1652,  0.7789,  0.8945,  0.5416,  0.4938,  0.9218,\n",
      "          0.7389,  0.3351,  0.2667,  0.8549,  0.6771,  0.7327,  0.9703],\n",
      "        [ 0.2649, -0.5148, -1.7510, -0.1913, -0.5488,  1.3885,  0.6922,  0.3423,\n",
      "          0.8375,  0.0085,  0.2313, -0.0244,  1.0849,  1.1587,  0.2736, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653, -0.3698,  0.0941,  0.2650, -1.1085,\n",
      "          0.1016,  0.2553,  1.9154, -0.3696,  0.8920, -0.9489, -0.9740,  0.4667,\n",
      "          1.7849,  1.0409, -0.3651,  0.2640,  1.1973,  0.2725, -0.2837,  0.1747,\n",
      "          2.1335, -0.3496,  0.8888,  0.1903,  0.2711,  0.3732,  0.3288, -1.5966,\n",
      "          1.0062, -0.2365,  0.5326, -1.4584,  0.4282, -1.4765, -0.2772,  0.1523,\n",
      "         -0.3435, -0.6364,  0.9847,  0.0473,  0.7524,  0.3026, -1.2232,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.4837,  0.5150,  0.2580,  0.2281,  0.3888,\n",
      "          0.1803,  0.3603,  0.5201,  0.3097,  0.3540,  0.3491,  0.3810]],\n",
      "       dtype=torch.float64, grad_fn=<StackBackward>)\n",
      "y: tensor([0, 0, 0, 0], dtype=torch.int32)\n",
      "i: 25000\n",
      "x: tensor([[ 0.2649,  1.8883,  0.0838, -0.5088, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.6047, -0.1394, -0.8685, -0.0244,  1.0849,  1.1587,  0.2736,  0.9547,\n",
      "         -1.1302,  0.1277,  1.6329,  0.3884, -2.0476,  1.8656, -0.1067, -0.4628,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653,  0.0035,  1.0454,  1.0058,  1.5420,\n",
      "         -1.1940, -0.2845,  0.3581,  0.8954, -0.9348,  1.1143,  2.4267, -0.4656,\n",
      "         -0.5813,  0.2559, -0.3651,  0.2640,  1.1973,  0.2725,  0.2494,  0.5759,\n",
      "         -2.5942, -1.1507,  0.5423, -0.4895, -0.9994,  1.1178, -1.1627, -0.7493,\n",
      "          1.5632, -1.0068, -0.1040, -2.0582, -0.2447,  0.0533,  1.6730,  0.1523,\n",
      "         -0.3435, -0.6364,  0.9847,  0.0473,  0.7524,  0.3026, -1.2232,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.1330,  0.4684,  0.1452,  0.3128,  0.3531,\n",
      "          0.0891,  0.5907,  0.5185,  0.2679,  0.3027,  0.1462,  0.4474],\n",
      "        [-0.6965,  0.1395,  0.2559,  0.8491, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.9232,  1.3783, -1.3629, -0.0244,  1.0849,  1.1587,  0.2736, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653, -0.7829, -0.3056, -0.8316, -1.1158,\n",
      "         -0.5914, -0.3370,  0.4090,  0.1764, -0.7283, -0.3273,  0.2224,  1.0174,\n",
      "         -0.8242, -1.4255, -1.3634, -0.8166, -0.0561, -0.1012, -0.6281,  0.4346,\n",
      "          0.6342,  1.6478,  2.0871,  0.7236, -0.6318,  1.1329,  0.5738,  0.7874,\n",
      "         -0.4283, -0.9146, -0.1673, -0.4464,  1.4584,  0.5198, -0.4802,  0.1523,\n",
      "         -0.3435, -0.6364,  0.9847,  0.0473,  0.7524,  0.3026, -1.2232,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.9440,  0.3594,  0.3323,  0.3988,  0.6440,\n",
      "          0.3158,  0.7382,  0.2074,  0.3788,  0.4145,  0.2376,  0.6376],\n",
      "        [ 0.2649,  0.4397, -0.1099, -0.5398,  1.4300,  1.1836,  0.2318,  0.6294,\n",
      "          0.8375,  0.0085,  0.2313,  0.8314,  0.7070, -0.2722,  0.4764, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "         -0.6001, -0.0530,  1.5956,  3.0022, -0.2109, -0.4759, -1.6508, -0.0199,\n",
      "          0.0851, -0.1437, -1.3086,  0.9403,  0.2486,  0.8529,  0.0668, -2.0715,\n",
      "          0.7918, -0.0487, -0.3651,  0.2640,  1.1973,  0.2725, -0.0504, -0.9621,\n",
      "          0.3112, -0.1255, -2.1254, -0.7884, -1.3551,  0.9819, -1.5523,  0.0447,\n",
      "          2.2219, -1.1354,  2.3416,  0.1510, -0.1176, -0.9061, -0.5625,  0.1523,\n",
      "         -0.3435, -0.6364,  0.9847,  0.0473,  0.7524, -1.2007,  0.9515,  0.6354,\n",
      "         -0.9992,  0.0278,  1.7245,  0.3406,  0.7509,  0.5240,  0.4600,  0.7436,\n",
      "          0.8812,  0.3994,  0.7924,  0.6714,  0.6343,  0.5709,  0.4628],\n",
      "        [ 0.2649,  1.0084,  0.2915, -0.3645,  0.2660,  0.2381, -1.2390,  0.0057,\n",
      "          0.8375,  0.0085,  0.2313, -0.0244,  1.0849,  1.1587,  0.2736, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "         -0.6992, -0.1991,  0.8427,  0.4096,  0.0153,  2.1411, -0.6937, -0.7705,\n",
      "         -0.6825, -1.7001, -0.4191, -0.3696,  0.8920, -0.9489, -0.9740,  0.4667,\n",
      "          1.7849,  1.0409, -0.3651,  0.2640,  1.1973,  0.2725, -0.2837,  0.1747,\n",
      "          2.1335, -0.3496,  0.8888,  0.1903,  0.2711,  0.3732,  0.3288, -1.5966,\n",
      "          1.0062, -0.2365,  0.5326, -1.4584,  0.4282, -1.4765, -0.2772, -0.4493,\n",
      "         -0.3435, -0.6364,  1.2252,  0.0473,  0.7524, -1.2007,  0.9515,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.6108,  0.4999,  0.1534,  0.1939,  0.3609,\n",
      "          0.8267,  0.8099,  0.6350,  0.2788,  0.4662,  0.3014,  0.3112]],\n",
      "       dtype=torch.float64, grad_fn=<StackBackward>)\n",
      "y: tensor([0, 0, 0, 1], dtype=torch.int32)\n",
      "i: 50000\n",
      "x: tensor([[-6.9649e-01,  4.3974e-01, -1.0993e-01, -5.3976e-01,  2.6599e-01,\n",
      "          2.3807e-01, -1.2390e+00,  5.6914e-03,  8.3750e-01,  8.4645e-03,\n",
      "          2.3129e-01, -2.4428e-02,  1.0849e+00,  1.1587e+00,  2.7360e-01,\n",
      "         -3.4389e-01,  7.3836e-01,  1.5573e+00, -8.0743e-01, -1.6828e+00,\n",
      "         -5.7936e-01,  5.3684e-01, -3.5020e-01,  1.4539e+00,  6.1113e-01,\n",
      "         -4.7155e-01, -1.4321e+00,  6.5348e-02,  1.0734e+00,  1.7986e-02,\n",
      "         -1.4252e+00,  3.2353e-03, -2.9422e-01, -4.0974e-01, -9.1508e-02,\n",
      "         -7.9135e-01, -1.3082e+00,  7.1919e-01,  5.6135e-01,  1.0560e-01,\n",
      "          1.5329e+00, -4.8015e-01, -3.6509e-01,  2.6401e-01,  1.1973e+00,\n",
      "          2.7247e-01, -2.8366e-01,  1.7474e-01,  2.1335e+00, -3.4963e-01,\n",
      "          8.8885e-01,  1.9033e-01,  2.7112e-01,  3.7319e-01,  3.2880e-01,\n",
      "         -1.5966e+00,  1.0062e+00, -2.3646e-01,  5.3260e-01, -1.4584e+00,\n",
      "          4.2822e-01, -1.4765e+00, -2.7724e-01,  1.5232e-01, -3.4354e-01,\n",
      "         -6.3641e-01,  9.8467e-01,  4.7257e-02,  7.5238e-01,  3.0255e-01,\n",
      "         -1.2232e+00,  1.3522e+00,  7.1042e-01, -1.8895e+00,  1.1652e+00,\n",
      "          9.0822e-02,  4.9133e-01,  2.4928e-01,  2.0402e-01,  6.1922e-01,\n",
      "          8.9358e-01,  9.3115e-01,  6.0620e-01,  2.7632e-01,  3.2408e-01,\n",
      "          4.7499e-01,  2.1328e-01],\n",
      "        [ 2.6494e-01, -5.1479e-01, -1.7510e+00, -1.9128e-01, -4.9128e-01,\n",
      "         -2.4970e+00, -1.6142e+00, -5.6671e-01,  8.3750e-01,  8.4645e-03,\n",
      "          2.3129e-01,  3.8216e-01, -1.6283e+00,  1.6023e+00, -2.8774e-01,\n",
      "         -3.4389e-01,  7.3836e-01,  1.5573e+00, -8.0743e-01, -1.6828e+00,\n",
      "         -5.7936e-01,  5.3684e-01, -3.5020e-01,  1.4539e+00, -4.0931e-01,\n",
      "         -1.2724e+00, -1.2510e+00,  7.7306e-02, -1.0822e-02,  2.1446e+00,\n",
      "          2.8675e+00,  1.0633e+00, -6.1513e-01,  4.9926e-01, -1.2722e+00,\n",
      "          1.0864e+00, -1.1546e-01,  1.7000e-01,  1.6035e-01,  5.0193e-01,\n",
      "         -1.6318e+00, -1.0163e+00, -3.6509e-01,  2.6401e-01,  1.1973e+00,\n",
      "          2.7247e-01, -5.8499e-01, -2.4860e-01, -7.5704e-01, -1.9184e+00,\n",
      "         -1.3309e-01, -1.2186e-01, -1.9125e-01, -1.0291e-02,  1.7617e-01,\n",
      "         -7.6261e-01, -1.3660e+00, -6.0989e-01, -1.6760e-01,  4.9271e-01,\n",
      "         -6.6712e-01,  4.7772e-01, -4.2566e-01,  1.5232e-01, -3.4354e-01,\n",
      "         -6.3641e-01,  9.8467e-01,  8.3940e-01,  2.2171e-02, -1.2007e+00,\n",
      "          9.5150e-01,  6.3535e-01, -9.9917e-01,  2.7767e-02,  1.7245e+00,\n",
      "          9.4986e-01,  4.9419e-01,  9.1092e-01,  9.5238e-01,  1.2729e-01,\n",
      "          7.4115e-01,  9.2042e-01,  8.1822e-01,  3.5410e-01,  8.8236e-01,\n",
      "          1.6017e-01,  4.6203e-01],\n",
      "        [ 2.6494e-01, -1.1144e+00, -5.5198e-01, -2.1569e-01, -4.9128e-01,\n",
      "         -2.4970e+00, -1.6142e+00, -5.6671e-01,  8.3750e-01,  8.4645e-03,\n",
      "          2.3129e-01,  8.3143e-01,  7.0703e-01, -2.7223e-01,  4.7644e-01,\n",
      "         -3.4389e-01,  7.3836e-01,  1.5573e+00, -8.0743e-01, -1.6828e+00,\n",
      "         -5.7936e-01,  5.3684e-01, -3.5020e-01,  1.4539e+00,  6.1113e-01,\n",
      "         -4.7155e-01, -1.4321e+00,  6.5348e-02, -1.8113e-01,  8.4601e-01,\n",
      "          1.0334e+00,  7.0901e-03,  2.4760e+00,  3.6102e-01,  5.6435e-01,\n",
      "         -3.6959e-01,  8.9195e-01, -9.4886e-01, -9.7403e-01,  4.6671e-01,\n",
      "          1.7849e+00,  1.0409e+00, -1.1666e+00,  1.0281e+00,  1.7278e+00,\n",
      "          2.8744e+00, -5.0417e-02, -9.6210e-01,  3.1122e-01, -1.2553e-01,\n",
      "         -2.1254e+00, -7.8838e-01, -1.3551e+00,  9.8189e-01, -1.5523e+00,\n",
      "          4.4708e-02,  2.2219e+00, -1.1354e+00,  2.3416e+00,  1.5098e-01,\n",
      "         -1.1763e-01, -9.0613e-01, -5.6246e-01,  1.5232e-01, -3.4354e-01,\n",
      "         -6.3641e-01,  9.8467e-01,  4.7257e-02,  7.5238e-01,  3.0255e-01,\n",
      "         -1.2232e+00,  1.3522e+00,  7.1042e-01, -1.8895e+00,  1.1652e+00,\n",
      "          7.7366e-02,  3.7271e-01,  6.5905e-01,  6.4862e-01,  3.5632e-01,\n",
      "          7.2977e-01,  8.0711e-01,  7.7694e-01,  6.0314e-01,  4.2120e-01,\n",
      "          7.6443e-01,  1.5334e-01],\n",
      "        [ 2.6494e-01, -5.1479e-01, -1.7510e+00, -1.9128e-01, -4.9128e-01,\n",
      "         -2.4970e+00, -1.6142e+00, -5.6671e-01,  8.3750e-01,  8.4645e-03,\n",
      "          2.3129e-01,  1.4823e+00, -1.0652e-01,  8.9024e-01,  5.5748e-01,\n",
      "         -3.4389e-01,  7.3836e-01,  1.5573e+00, -8.0743e-01, -1.6828e+00,\n",
      "         -5.7936e-01,  5.3684e-01, -3.5020e-01,  1.4539e+00,  6.1113e-01,\n",
      "         -4.7155e-01, -1.4321e+00,  6.5348e-02,  5.2205e-01, -1.0674e+00,\n",
      "          2.2597e-01,  1.8502e-01,  1.2074e+00, -5.8679e-01, -4.1333e-01,\n",
      "          2.3551e-03,  1.5631e-01,  1.3799e-01, -2.5221e+00,  5.5079e-01,\n",
      "          3.3092e-02, -4.1983e-01, -9.7721e-02,  1.3711e-01, -3.1779e-01,\n",
      "         -5.5994e-01, -1.0111e+00,  1.2108e-01,  2.7457e-01,  1.3552e-01,\n",
      "          1.8240e+00, -1.3585e+00, -1.8481e+00,  4.0305e-02, -1.6404e-01,\n",
      "          6.9343e-01,  1.9502e-01,  1.5125e-01, -1.0443e+00,  3.0669e-01,\n",
      "         -4.8683e-01,  9.9141e-01, -1.4307e+00,  1.5232e-01, -1.2131e+00,\n",
      "         -6.3641e-01,  9.8467e-01,  4.7257e-02,  7.5238e-01,  3.0255e-01,\n",
      "         -1.2232e+00,  1.3522e+00,  7.1042e-01, -1.8895e+00,  1.1652e+00,\n",
      "          8.7599e-01,  5.1653e-01,  5.4456e-01,  5.2047e-01,  2.6100e-01,\n",
      "          3.0729e-01,  4.4417e-01,  6.1593e-01,  3.6740e-01,  8.0507e-01,\n",
      "          2.2479e-01,  3.2540e-01]], dtype=torch.float64,\n",
      "       grad_fn=<StackBackward>)\n",
      "y: tensor([0, 1, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "trainloader,testloader = LoadData()\n",
    "# # print(\"cd.categoricals:\",cd.categoricals,\"\\n\",\"cd.embeddings:\",cd.embeddings,\"\\n\",\"cd.vectors.shape:\",cd.vectors.shape)\n",
    "i = 0\n",
    "for x,y in trainloader:\n",
    "    if not i%25000:\n",
    "        print(\"i:\",i)\n",
    "        print(\"x:\",x)\n",
    "        print(\"y:\",y)\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "colored-force",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300000, 87])\n"
     ]
    }
   ],
   "source": [
    "print(trainloader.dataset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polar-laser",
   "metadata": {
    "tags": []
   },
   "source": [
    "# train_set_x = (trainloader.dataset)[:][0]\n",
    "r = torch.load('train_set_x.pt')\n",
    "print(r[200000:200004])\n",
    "# train_set_y = (trainloader.dataset)[:][1]\n",
    "e = torch.load('train_set_y.pt')\n",
    "print(e[200000:200004])\n",
    "# numpy.save('data/train_set_x.pt',(trainloader.dataset)[:][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-durham",
   "metadata": {
    "tags": []
   },
   "source": [
    "d = OrderedDict()\n",
    "d[1] = \"hi\"\n",
    "d[\"2\"] = \"hi\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-irrigation",
   "metadata": {
    "tags": []
   },
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "massive-craps",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1e3c70b1a990>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mmodel_wrapper\u001b[0m      \u001b[0;31m# this decorator should be put on the out most PyTorch module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msignal_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Source/kaggle/tabular-playground-series-mar-2021/toolbox/lib/python3.9/site-packages/nni/retiarii/serializer.py\u001b[0m in \u001b[0;36mmodel_wrapper\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;36m2.\u001b[0m \u001b[0mReset\u001b[0m \u001b[0muid\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmutation\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mnamespace\u001b[0m \u001b[0mso\u001b[0m \u001b[0mthat\u001b[0m \u001b[0meach\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mCan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0museful\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munittest\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m \u001b[0mmulti\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0mscenarios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_create_wrapper_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_mutation_uid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_parsing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Source/kaggle/tabular-playground-series-mar-2021/toolbox/lib/python3.9/site-packages/nni/retiarii/serializer.py\u001b[0m in \u001b[0;36m_create_wrapper_cls\u001b[0;34m(cls, store_init_parameters, reset_mutation_uid, stop_parsing)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_module_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Source/kaggle/tabular-playground-series-mar-2021/toolbox/lib/python3.9/site-packages/nni/retiarii/utils.py\u001b[0m in \u001b[0;36mget_module_name\u001b[0;34m(cls_or_func)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# infer the module name with inspect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfrm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0;31m# main module found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mmain_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsourcefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "# # Define model search space\n",
    "# import torch.nn.functional as F\n",
    "# import nni.retiarii.nn.pytorch as nn\n",
    "# from nni.retiarii import model_wrapper\n",
    "\n",
    "class FullConn(nn.Module):\n",
    "    def __init__(self,signal):\n",
    "        out_features = nn.ValueChoice(range(2**10+1))\n",
    "        num_groups = nn.ValueChoice(range(2, o_f/2+1))\n",
    "        p = nn.ValueChoice(range(0.5,0.91,0.01))\n",
    "        \n",
    "        self.linear = nn.Linear(\n",
    "            in_features = signal.shape[-1],\n",
    "            out_features = out_features\n",
    "        )\n",
    "        self.norm = nn.GroupNorm(\n",
    "            num_groups = num_groups,\n",
    "            num_channels = o_f\n",
    "        )        \n",
    "        self.use_dropout = nn.ValueChoice([0,1])\n",
    "        if (self.use_dropout):\n",
    "            self.drop = nn.Dropout(p = p)\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.norm(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        if (self.use_dropout): x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Soft(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "    def forward(self, x):\n",
    "        return self.softmax(x)\n",
    "\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self,signal_size,output_size):\n",
    "        super().__init__()\n",
    "#         signal_tensor = torch.load('train_set_x.pt')\n",
    "        stack = OrderedDict()\n",
    "        layer_count = nn.ValueChoice(range(2,2**10+1))\n",
    "#         signal = signal_tensor.shape[-1]\n",
    "#         i = 0\n",
    "        for l in range(layer_count):\n",
    "#             index = \"{}\".format(i)\n",
    "            stack[len(stack)] = FullConn(signal_size)\n",
    "#             i += 1\n",
    "#             stack[len(stack)] = Drop()\n",
    "        stack[len(stack)] = Soft()\n",
    "        self.fc = nn.Sequential(stack)\n",
    "\n",
    "@model_wrapper      # this decorator should be put on the out most PyTorch module\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,signal_size,output_size):\n",
    "        super().__init__()\n",
    "#         signal_tensor = torch.load('train_set_x.pt')\n",
    "        stack = OrderedDict()\n",
    "        layer_count = nn.ValueChoice(range(2,2**10+1))\n",
    "#         signal = signal_tensor.shape[-1]\n",
    "#         i = 0\n",
    "        for l in range(layer_count):\n",
    "#             index = \"{}\".format(i)\n",
    "            stack[len(stack)] = FullConn(signal_size)\n",
    "#             i += 1\n",
    "#             stack[len(stack)] = Drop()\n",
    "        stack[len(stack)] = Soft()\n",
    "        self.fc = nn.Sequential(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surgical-strain",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_training_hyperparameters():\n",
    "    lr = {\n",
    "        \"name\":\"learning rate {10^(-âŒŠxâŒ‹)\",\n",
    "        \"bounds\":[x for x in range(1,4)]\n",
    "    }\n",
    "    batch_size = {\n",
    "        \"name\":\"batch size {2^âŒŠxâŒ‹}\",\n",
    "        \"bounds\":[x for x in range(6,9)]\n",
    "    }\n",
    "    epochs = {\n",
    "        \"name\":\"epochs {10âŒŠxâŒ‹}\",\n",
    "        \"bounds\":[x for x in range(2,6)]\n",
    "    }\n",
    "    \n",
    "    config_space = CS.ConfigurationSpace()\n",
    "    config_space_dict,config_space_ray = {},{}\n",
    "    \n",
    "    #start ConfigSpace API\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(\n",
    "            lr[\"name\"],\n",
    "            lr[\"bounds\"][0],\n",
    "            lr[\"bounds\"][-1],\n",
    "            log=True\n",
    "        ))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(\n",
    "            batch_size[\"name\"], \n",
    "            batch_size[\"bounds\"]\n",
    "        ))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(\n",
    "            epochs[\"name\"], \n",
    "            epochs[\"bounds\"]\n",
    "        ))\n",
    "    \n",
    "    #start Ray Search Space API\n",
    "    config_space_ray[lr[\"name\"]] = tune.loguniform(lr[\"bounds\"][0],lr[\"bounds\"][-1])\n",
    "    config_space_ray[batch_size[\"name\"]] = tune.choice(batch_size[\"bounds\"])\n",
    "    config_space_ray[epochs[\"name\"]] = tune.choice(categories=epochs[\"bounds\"])\n",
    "    \n",
    "    #start Dragonfly Search Space API\n",
    "    param_list = [\n",
    "        {\n",
    "            \"name\": lr[\"name\"], \n",
    "            \"type\": \"float\", \n",
    "            \"min\": lr[\"bounds\"][0], \n",
    "            \"max\": lr[\"bounds\"][-1]\n",
    "        },\n",
    "        {\n",
    "            \"name\": batch_size[\"name\"], \n",
    "            \"type\": \"discrete_numeric\", \n",
    "            \"items\": \":\".join([str(2**x) for x in batch_size[\"bounds\"]])\n",
    "        },\n",
    "        {\n",
    "            \"name\": epochs[\"name\"], \n",
    "            \"type\": \"discrete_numeric\", \n",
    "            \"items\": \":\".join([str(10*x) for x in epochs[\"bounds\"]])\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    #start BayesOpt Search Space API\n",
    "    config_space_dict[lr[\"name\"]] = tune.uniform(lr[\"bounds\"][0],lr[\"bounds\"][-1])\n",
    "    config_space_dict[batch_size[\"name\"]] = tune.uniform(lower=batch_size[\"bounds\"][0], upper=batch_size[\"bounds\"][-1])\n",
    "    config_space_dict[epochs[\"name\"]] = tune.uniform(lower=epochs[\"bounds\"][0], upper=epochs[\"bounds\"][-1])\n",
    "    \n",
    "    #start Discrete Search Search Space API\n",
    "    param_dict = {p[\"name\"]:p[\"bounds\"] for p in [lr,batch_size,epochs]}\n",
    "    \n",
    "    #start PB2 Space API\n",
    "    min_max_param_dict = {p[\"name\"]:[p[\"bounds\"][0], p[\"bounds\"][-1]] for p in [lr,batch_size,epochs]}\n",
    "    \n",
    "    return config_space_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
