{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flush-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "filled-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import Kaggle data\n",
    "# import kaggle\n",
    "# kagggle competitions download tabular-playground-series-mar-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "saving-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to memory for discovery\n",
    "train,test = pd.read_csv('./train.csv',index_col=\"id\"),pd.read_csv('./test.csv',index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "large-sheriff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 0 to 499999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   cat0    300000 non-null  object \n",
      " 1   cat1    300000 non-null  object \n",
      " 2   cat2    300000 non-null  object \n",
      " 3   cat3    300000 non-null  object \n",
      " 4   cat4    300000 non-null  object \n",
      " 5   cat5    300000 non-null  object \n",
      " 6   cat6    300000 non-null  object \n",
      " 7   cat7    300000 non-null  object \n",
      " 8   cat8    300000 non-null  object \n",
      " 9   cat9    300000 non-null  object \n",
      " 10  cat10   300000 non-null  object \n",
      " 11  cat11   300000 non-null  object \n",
      " 12  cat12   300000 non-null  object \n",
      " 13  cat13   300000 non-null  object \n",
      " 14  cat14   300000 non-null  object \n",
      " 15  cat15   300000 non-null  object \n",
      " 16  cat16   300000 non-null  object \n",
      " 17  cat17   300000 non-null  object \n",
      " 18  cat18   300000 non-null  object \n",
      " 19  cont0   300000 non-null  float64\n",
      " 20  cont1   300000 non-null  float64\n",
      " 21  cont2   300000 non-null  float64\n",
      " 22  cont3   300000 non-null  float64\n",
      " 23  cont4   300000 non-null  float64\n",
      " 24  cont5   300000 non-null  float64\n",
      " 25  cont6   300000 non-null  float64\n",
      " 26  cont7   300000 non-null  float64\n",
      " 27  cont8   300000 non-null  float64\n",
      " 28  cont9   300000 non-null  float64\n",
      " 29  cont10  300000 non-null  float64\n",
      " 30  target  300000 non-null  int64  \n",
      "dtypes: float64(11), int64(1), object(19)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get data structure\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "empirical-namibia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>Q</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759439</td>\n",
       "      <td>0.795549</td>\n",
       "      <td>0.681917</td>\n",
       "      <td>0.621672</td>\n",
       "      <td>0.592184</td>\n",
       "      <td>0.791921</td>\n",
       "      <td>0.815254</td>\n",
       "      <td>0.965006</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>K</td>\n",
       "      <td>W</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386385</td>\n",
       "      <td>0.541366</td>\n",
       "      <td>0.388982</td>\n",
       "      <td>0.357778</td>\n",
       "      <td>0.600044</td>\n",
       "      <td>0.408701</td>\n",
       "      <td>0.399353</td>\n",
       "      <td>0.927406</td>\n",
       "      <td>0.493729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BM</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343255</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.793687</td>\n",
       "      <td>0.552877</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.388835</td>\n",
       "      <td>0.412303</td>\n",
       "      <td>0.292696</td>\n",
       "      <td>0.549452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831147</td>\n",
       "      <td>0.807807</td>\n",
       "      <td>0.800032</td>\n",
       "      <td>0.619147</td>\n",
       "      <td>0.221789</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.633669</td>\n",
       "      <td>0.760318</td>\n",
       "      <td>0.934242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338818</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.610578</td>\n",
       "      <td>0.128291</td>\n",
       "      <td>0.578764</td>\n",
       "      <td>0.279167</td>\n",
       "      <td>0.351103</td>\n",
       "      <td>0.357084</td>\n",
       "      <td>0.328960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont2     cont3  \\\n",
       "id                                                    ...                       \n",
       "0     A    I    A    B    B   BI    A    S    Q    A  ...  0.759439  0.795549   \n",
       "1     A    I    A    A    E   BI    K    W   AD    F  ...  0.386385  0.541366   \n",
       "2     A    K    A    A    E   BI    A    E   BM    L  ...  0.343255  0.616352   \n",
       "3     A    K    A    C    E   BI    A    Y   AD    F  ...  0.831147  0.807807   \n",
       "4     A    I    G    B    E   BI    C    G    Q    A  ...  0.338818  0.277308   \n",
       "\n",
       "       cont4     cont5     cont6     cont7     cont8     cont9    cont10  \\\n",
       "id                                                                         \n",
       "0   0.681917  0.621672  0.592184  0.791921  0.815254  0.965006  0.665915   \n",
       "1   0.388982  0.357778  0.600044  0.408701  0.399353  0.927406  0.493729   \n",
       "2   0.793687  0.552877  0.352113  0.388835  0.412303  0.292696  0.549452   \n",
       "3   0.800032  0.619147  0.221789  0.897617  0.633669  0.760318  0.934242   \n",
       "4   0.610578  0.128291  0.578764  0.279167  0.351103  0.357084  0.328960   \n",
       "\n",
       "    target  \n",
       "id          \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at data examples\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "great-engineer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categroy with median total unique values:\n",
      " cat3 :  13 unique values\n"
     ]
    }
   ],
   "source": [
    "# Get number of unique categories\n",
    "cal_cols = train.select_dtypes('object')\n",
    "cal_cols_keys = cal_cols.keys()\n",
    "# cal_cols_vals = np.array((cal_cols.values))\n",
    "\n",
    "#Build sample item\n",
    "cat_stats = np.array([train[c].nunique() for c in cal_cols])\n",
    "median_cat = math.ceil(np.median(cat_stats))\n",
    "target_cat_index = int(np.where(cat_stats == median_cat)[0])\n",
    "target_cat_name = cal_cols_keys[target_cat_index]\n",
    "\n",
    "print(\"Categroy with median total unique values:\\n\",target_cat_name,\": \",train[target_cat_name].nunique(),\"unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confused-bonus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat3 indices:\n",
      " {'B': 0, 'A': 1, 'C': 2, 'D': 3, 'G': 4, 'N': 5, 'H': 6, 'F': 7, 'E': 8, 'K': 9, 'I': 10, 'J': 11, 'L': 12}\n"
     ]
    }
   ],
   "source": [
    "# Index categories\n",
    "categoricals_to_ix = {}\n",
    "\n",
    "for c in train.select_dtypes('object'):\n",
    "    categoricals_to_ix[c] = {cat:i for i,cat in enumerate(train[c].unique())}\n",
    "\n",
    "#Confirm with sample indexing\n",
    "sample_cat = categoricals_to_ix[target_cat_name]\n",
    "print(target_cat_name,\"indices:\\n\",sample_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "filled-marshall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanple cat3 category:\n",
      " H\n",
      "Sanple category embedding:\n",
      " tensor([[ 2.3227, -0.9644, -0.3908]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Test embeddings\n",
    "test_embeds = {}\n",
    "\n",
    "for cix_key in categoricals_to_ix.keys():\n",
    "    cix = categoricals_to_ix[cix_key]\n",
    "    bag_size = len(cix)\n",
    "    embed_size = math.isqrt(bag_size) #hyperparameter to optimize later\n",
    "    test_embeds[cix_key] = nn.Embedding(bag_size,embed_size)\n",
    "\n",
    "#Confirm with sample embedding\n",
    "target_cat_keys = list(sample_cat.keys())\n",
    "target_cat_vals = np.array(list(sample_cat.values()))\n",
    "target_cat_vals_median = math.ceil(np.median(target_cat_vals))\n",
    "target_cat_keys_sample = target_cat_keys[target_cat_vals_median]\n",
    "print(\"Sanple\",target_cat_name,\"category:\\n\",target_cat_keys_sample)\n",
    "    \n",
    "testor = torch.tensor([categoricals_to_ix[target_cat_name][target_cat_keys_sample]], dtype=torch.long)\n",
    "cat_keys_sample_hash = test_embeds[target_cat_name](testor)\n",
    "print(\"Sanple category embedding:\\n\",cat_keys_sample_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "immediate-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embeddings content (dictionary and translations)\n",
    "#function to build embeddings library\n",
    "#function assumes only categorical features are fed in\n",
    "def BuildEmbedlibrary(features):\n",
    "    categoricals_to_ix,embeds = {},{}\n",
    "    \n",
    "    #Build category index\n",
    "    for c in features:\n",
    "        categoricals_to_ix[c] = {cat:i for i,cat in enumerate(train[c].unique())}\n",
    "    \n",
    "    #Create embeddings for each feature\n",
    "    for cix_key in categoricals_to_ix.keys():\n",
    "        cix = categoricals_to_ix[cix_key]\n",
    "        bag_size = len(cix)\n",
    "        embed_size = math.isqrt(bag_size) #hyperparameter to optimize later\n",
    "        embeds[cix_key] = nn.Embedding(bag_size,embed_size)\n",
    "    \n",
    "#         print(embeds[cix_key])\n",
    "    return categoricals_to_ix,embeds\n",
    "\n",
    "#function that gets respective embedding for given feature value\n",
    "def CatToSubvector(category,feature_name,categorical_library,embedding_library,verbose=False):\n",
    "#     if verbose:\n",
    "#         print(verbose)\n",
    "#         for info in [categorical_library]:\n",
    "# #         for info in [category,feature_name,categorical_library,embedding_library]:\n",
    "#             print(info,\"\\n\")\n",
    "#     [print(valu,\"\\n\") for valu in [category,feature_name,categorical_library,embedding_library]]\n",
    "    raw_idx = torch.tensor([categorical_library[feature_name][category]], dtype=torch.long)\n",
    "#     if (verbose): print(\"embedding_library[feature_name]:\",embedding_library[feature_name],\"\\n\",\"raw_idx:\",raw_idx)\n",
    "    emb = embedding_library[feature_name](raw_idx)\n",
    "#     if (verbose): print(\"embedding_library[feature_name](raw_idx):\",emb,\"\\n\")\n",
    "#     subvector = torch.Tensor(emb)\n",
    "#     if (verbose): print(\"subvector:\",subvector)\n",
    "    \n",
    "#     return subvector\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "norman-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Confirm function structure\n",
    "# test_cat_dict,test_embeddings = BuildEmbedlibrary(train.select_dtypes('object'))\n",
    "# test_subvec = CatToSubvector(target_cat_keys_sample,target_cat_name,test_cat_dict,test_embeddings)\n",
    "\n",
    "# # print(\"Sanple category embedding:\\n\",test_subvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "allied-chorus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data\n",
    "\n",
    "#define dataset\n",
    "class ClaimsDataset(Dataset):\n",
    "    def __init__(self, csv_path='./train.csv'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            raw_data (dataframe): Dataframe with raw featurres and labels.\n",
    "        \"\"\"\n",
    "#         self.categoricals,self.embeddings = {},{}\n",
    "        raw_data = pd.read_csv(csv_path)\n",
    "        \n",
    "#         self.l = len(raw_data)\n",
    "        self.target = raw_data.pop('target')\n",
    "        categorical_features = raw_data.select_dtypes(include='object')\n",
    "        noncategorical_features = raw_data.select_dtypes(exclude='object')\n",
    "        \n",
    "        self.categoricals,self.embeddings = BuildEmbedlibrary(categorical_features)\n",
    "        \n",
    "        subvects = DataFrame()\n",
    "#         for row in categorical_features.values:\n",
    "#             subsubvects = []\n",
    "#             for v,c in zip(row,categorical_features.columns):\n",
    "#                 subsubvects.append(CatToSubvector(v,c,self.categoricals,self.embeddings))\n",
    "# #             [print(\"subsubvect size:\",ssv.size()) for ssv in subsubvects]\n",
    "#             subvects.append(torch.cat(subsubvects,1))\n",
    "\n",
    "        subsubvects = []\n",
    "        for col in categorical_features.columns:\n",
    "            cat_col = (categorical_features[col]).tolist()\n",
    "#             print(\"cat_col:\",cat_col,\"\\n\")\n",
    "#             cat_emb = cat_col\n",
    "#             cat_emb = cat_col.apply(lambda x: CatToSubvector(x,col,self.categoricals,self.embeddings,True))\n",
    "#             if (i%2):# == 0 and i!=0):\n",
    "#                 print(\"i:\",i)\n",
    "#                 cat_emb = cat_col.apply(lambda x: CatToSubvector(x,col,self.categoricals,self.embeddings,True))\n",
    "#                 print(\"cat_emb:\",cat_emb,\"\\n\")\n",
    "#             else:\n",
    "#                 cat_emb = cat_col.apply(lambda x: CatToSubvector(x,col,self.categoricals,self.embeddings,False))\n",
    "            cat_embs = CatToSubvector(cat_col[0],col,self.categoricals,self.embeddings)\n",
    "            for x in cat_col[1:]:\n",
    "                new_emb = CatToSubvector(x,col,self.categoricals,self.embeddings)\n",
    "                cat_embs = torch.cat((cat_embs,new_emb))\n",
    "#             cat_emb = [CatToSubvector(x,col,self.categoricals,self.embeddings) for x in cat_col]\n",
    "#             print(col,\"cat_embs.shape:\",cat_embs.shape,\"\\n\")\n",
    "#             cat_emb = torch.cat(tuple(cat_emb))\n",
    "#             print(\"type(cat_emb[-10]):\",type(cat_emb[-10]),\"\\n\")\n",
    "#             print(\"cat_emb[-10]:\",cat_emb[-10],\"\\n\")\n",
    "            subsubvects.append(cat_embs)\n",
    "            \n",
    "#         print(\"tuple(subsubvects):\",tuple(subsubvects),\"\\n\")\n",
    "        subvects = torch.cat(tuple(subsubvects),1)\n",
    "#         print(\"subvects[1]:\",subvects[1],\"\\n\")\n",
    "#         print(\"subvects.shape:\",subvects.shape,\"\\n\")\n",
    "\n",
    "\n",
    "        \n",
    "        # copy the data \n",
    "        df_min_max_scaled = noncategorical_features.copy() \n",
    "\n",
    "        # apply normalization techniques by Column 1 \n",
    "        for col in df_min_max_scaled.columns:\n",
    "            df_min_max_scaled[col] = (df_min_max_scaled[col] - df_min_max_scaled[col].min()) / (df_min_max_scaled[col].max() - df_min_max_scaled[col].min())\n",
    "\n",
    "#         noncat_mean = noncategorical_features.mean(1)\n",
    "#         noncat_std = noncategorical_features.std(1)\n",
    "        \n",
    "        \n",
    "        self.data = torch.cat((\n",
    "            subvects,\n",
    "            torch.tensor(noncategorical_features.values)\n",
    "        ),1)\n",
    "        \n",
    "        print(\"self.vectors:\",self.vectors,\"\\n\")\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "            \n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rental-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(batch_size_order=2):\n",
    "    bs = 2*batch_size_order\n",
    "    train_set,test_set = ClaimsDataset('./train.csv'),ClaimsDataset('./test.csv')\n",
    "    train_loader,test_loader = DataLoader(claimset,batch_size=bs,shuffle=True)\n",
    "    \n",
    "    return trainloader,testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader,testloader = LoadData()\n",
    "# print(\"cd.categoricals:\",cd.categoricals,\"\\n\",\"cd.embeddings:\",cd.embeddings,\"\\n\",\"cd.vectors.shape:\",cd.vectors.shape)\n",
    "x,y = trainloader[0]\n",
    "print(\"x:\",x)\n",
    "print(\"y:\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
