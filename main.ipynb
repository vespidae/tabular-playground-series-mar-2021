{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decimal-bulletin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import nni\n",
    "import torch.nn.functional as F\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "from nni.retiarii import model_wrapper\n",
    "\n",
    "from os.path import exists\n",
    "\n",
    "import ray\n",
    "from ray import tune # for trialing\n",
    "from ray.tune import JupyterNotebookReporter # for trial reporting\n",
    "# from ray.tune.integration.torch import is_distributed_trainable\n",
    "# from torch.nn.parallel import DistributedDataParallel\n",
    "# from ray.tune.integration.torch import DistributedTrainableCreator\n",
    "# from ray.tune.integration.torch import distributed_checkpoint_dir\n",
    "from ray.tune.schedulers import ASHAScheduler # for trial scheduling\n",
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray.tune.suggest.bayesopt import BayesOptSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seven-shark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import Kaggle data\n",
    "# import kaggle\n",
    "# kagggle competitions download tabular-playground-series-mar-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extended-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to memory for discovery\n",
    "train,test = pd.read_csv('./train.csv',index_col=\"id\"),pd.read_csv('./test.csv',index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "satisfactory-category",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 300000 entries, 0 to 499999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   cat0    300000 non-null  object \n",
      " 1   cat1    300000 non-null  object \n",
      " 2   cat2    300000 non-null  object \n",
      " 3   cat3    300000 non-null  object \n",
      " 4   cat4    300000 non-null  object \n",
      " 5   cat5    300000 non-null  object \n",
      " 6   cat6    300000 non-null  object \n",
      " 7   cat7    300000 non-null  object \n",
      " 8   cat8    300000 non-null  object \n",
      " 9   cat9    300000 non-null  object \n",
      " 10  cat10   300000 non-null  object \n",
      " 11  cat11   300000 non-null  object \n",
      " 12  cat12   300000 non-null  object \n",
      " 13  cat13   300000 non-null  object \n",
      " 14  cat14   300000 non-null  object \n",
      " 15  cat15   300000 non-null  object \n",
      " 16  cat16   300000 non-null  object \n",
      " 17  cat17   300000 non-null  object \n",
      " 18  cat18   300000 non-null  object \n",
      " 19  cont0   300000 non-null  float64\n",
      " 20  cont1   300000 non-null  float64\n",
      " 21  cont2   300000 non-null  float64\n",
      " 22  cont3   300000 non-null  float64\n",
      " 23  cont4   300000 non-null  float64\n",
      " 24  cont5   300000 non-null  float64\n",
      " 25  cont6   300000 non-null  float64\n",
      " 26  cont7   300000 non-null  float64\n",
      " 27  cont8   300000 non-null  float64\n",
      " 28  cont9   300000 non-null  float64\n",
      " 29  cont10  300000 non-null  float64\n",
      " 30  target  300000 non-null  int64  \n",
      "dtypes: float64(11), int64(1), object(19)\n",
      "memory usage: 73.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get data structure\n",
    "train.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "clean-tiffany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>...</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>Q</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759439</td>\n",
       "      <td>0.795549</td>\n",
       "      <td>0.681917</td>\n",
       "      <td>0.621672</td>\n",
       "      <td>0.592184</td>\n",
       "      <td>0.791921</td>\n",
       "      <td>0.815254</td>\n",
       "      <td>0.965006</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>K</td>\n",
       "      <td>W</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386385</td>\n",
       "      <td>0.541366</td>\n",
       "      <td>0.388982</td>\n",
       "      <td>0.357778</td>\n",
       "      <td>0.600044</td>\n",
       "      <td>0.408701</td>\n",
       "      <td>0.399353</td>\n",
       "      <td>0.927406</td>\n",
       "      <td>0.493729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BM</td>\n",
       "      <td>L</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343255</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.793687</td>\n",
       "      <td>0.552877</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.388835</td>\n",
       "      <td>0.412303</td>\n",
       "      <td>0.292696</td>\n",
       "      <td>0.549452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831147</td>\n",
       "      <td>0.807807</td>\n",
       "      <td>0.800032</td>\n",
       "      <td>0.619147</td>\n",
       "      <td>0.221789</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.633669</td>\n",
       "      <td>0.760318</td>\n",
       "      <td>0.934242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338818</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.610578</td>\n",
       "      <td>0.128291</td>\n",
       "      <td>0.578764</td>\n",
       "      <td>0.279167</td>\n",
       "      <td>0.351103</td>\n",
       "      <td>0.357084</td>\n",
       "      <td>0.328960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9  ...     cont2     cont3  \\\n",
       "id                                                    ...                       \n",
       "0     A    I    A    B    B   BI    A    S    Q    A  ...  0.759439  0.795549   \n",
       "1     A    I    A    A    E   BI    K    W   AD    F  ...  0.386385  0.541366   \n",
       "2     A    K    A    A    E   BI    A    E   BM    L  ...  0.343255  0.616352   \n",
       "3     A    K    A    C    E   BI    A    Y   AD    F  ...  0.831147  0.807807   \n",
       "4     A    I    G    B    E   BI    C    G    Q    A  ...  0.338818  0.277308   \n",
       "\n",
       "       cont4     cont5     cont6     cont7     cont8     cont9    cont10  \\\n",
       "id                                                                         \n",
       "0   0.681917  0.621672  0.592184  0.791921  0.815254  0.965006  0.665915   \n",
       "1   0.388982  0.357778  0.600044  0.408701  0.399353  0.927406  0.493729   \n",
       "2   0.793687  0.552877  0.352113  0.388835  0.412303  0.292696  0.549452   \n",
       "3   0.800032  0.619147  0.221789  0.897617  0.633669  0.760318  0.934242   \n",
       "4   0.610578  0.128291  0.578764  0.279167  0.351103  0.357084  0.328960   \n",
       "\n",
       "    target  \n",
       "id          \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Peek at data examples\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "apart-contributor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categroy with median total unique values:\n",
      " cat3 :  13 unique values\n"
     ]
    }
   ],
   "source": [
    "# Get number of unique categories\n",
    "cal_cols = train.select_dtypes('object')\n",
    "cal_cols_keys = cal_cols.keys()\n",
    "# cal_cols_vals = np.array((cal_cols.values))\n",
    "\n",
    "#Build sample item\n",
    "cat_stats = np.array([train[c].nunique() for c in cal_cols])\n",
    "median_cat = math.ceil(np.median(cat_stats))\n",
    "target_cat_index = int(np.where(cat_stats == median_cat)[0])\n",
    "target_cat_name = cal_cols_keys[target_cat_index]\n",
    "\n",
    "print(\"Categroy with median total unique values:\\n\",target_cat_name,\": \",train[target_cat_name].nunique(),\"unique values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "found-dressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat3 indices:\n",
      " {'B': 0, 'A': 1, 'C': 2, 'D': 3, 'G': 4, 'N': 5, 'H': 6, 'F': 7, 'E': 8, 'K': 9, 'I': 10, 'J': 11, 'L': 12}\n"
     ]
    }
   ],
   "source": [
    "# Index categories\n",
    "categoricals_to_ix = {}\n",
    "\n",
    "for c in train.select_dtypes('object'):\n",
    "    categoricals_to_ix[c] = {cat:i for i,cat in enumerate(train[c].unique())}\n",
    "\n",
    "#Confirm with sample indexing\n",
    "sample_cat = categoricals_to_ix[target_cat_name]\n",
    "print(target_cat_name,\"indices:\\n\",sample_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "twelve-presence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanple cat3 category:\n",
      " H\n",
      "Sanple category embedding:\n",
      " tensor([[ 0.6965,  1.3737, -0.8574]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Test embeddings\n",
    "test_embeds = {}\n",
    "\n",
    "for cix_key in categoricals_to_ix.keys():\n",
    "    cix = categoricals_to_ix[cix_key]\n",
    "    bag_size = len(cix)\n",
    "    embed_size = math.isqrt(bag_size) #hyperparameter to optimize later\n",
    "    test_embeds[cix_key] = nn.Embedding(bag_size,embed_size)\n",
    "\n",
    "#Confirm with sample embedding\n",
    "target_cat_keys = list(sample_cat.keys())\n",
    "target_cat_vals = np.array(list(sample_cat.values()))\n",
    "target_cat_vals_median = math.ceil(np.median(target_cat_vals))\n",
    "target_cat_keys_sample = target_cat_keys[target_cat_vals_median]\n",
    "print(\"Sanple\",target_cat_name,\"category:\\n\",target_cat_keys_sample)\n",
    "    \n",
    "testor = torch.tensor([categoricals_to_ix[target_cat_name][target_cat_keys_sample]], dtype=torch.long)\n",
    "cat_keys_sample_hash = test_embeds[target_cat_name](testor)\n",
    "print(\"Sanple category embedding:\\n\",cat_keys_sample_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "intended-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define embeddings content (dictionary and translations)\n",
    "#function to build embeddings library\n",
    "#function assumes only categorical features are fed in\n",
    "def BuildEmbedlibrary(features):\n",
    "    categoricals_to_ix,embeds = {},{}\n",
    "    \n",
    "    #Build category index\n",
    "    for c in features:\n",
    "        categoricals_to_ix[c] = {cat:i for i,cat in enumerate(train[c].unique())}\n",
    "    \n",
    "    #Create embeddings for each feature\n",
    "    for cix_key in categoricals_to_ix.keys():\n",
    "        cix = categoricals_to_ix[cix_key]\n",
    "        bag_size = len(cix)\n",
    "        embed_size = math.isqrt(bag_size) #hyperparameter to optimize later\n",
    "        embeds[cix_key] = nn.Embedding(bag_size,embed_size)\n",
    "    \n",
    "#         print(embeds[cix_key])\n",
    "    return categoricals_to_ix,embeds\n",
    "\n",
    "#function that gets respective embedding for given feature value\n",
    "def CatToSubvector(category,feature_name,categorical_library,embedding_library,verbose=False):\n",
    "    if verbose:\n",
    "#         print(verbose)\n",
    "#         for info in [categorical_library]:\n",
    "# #         for info in [category,feature_name,categorical_library,embedding_library]:\n",
    "#             print(info,\"\\n\")\n",
    "        print(\"category: {}; feature_name: {}; categorical_library: {}; embedding_library: {}\".format(\n",
    "            category,\n",
    "            feature_name,\n",
    "            categorical_library,\n",
    "            embedding_library\n",
    "        ))\n",
    "#     [print(valu,\"\\n\") for valu in [category,feature_name,categorical_library,embedding_library]]\n",
    "    raw_idx = torch.tensor([categorical_library[feature_name][category]], dtype=torch.long)\n",
    "#     if (verbose): print(\"embedding_library[feature_name]:\",embedding_library[feature_name],\"\\n\",\"raw_idx:\",raw_idx)\n",
    "    emb = embedding_library[feature_name](raw_idx)\n",
    "#     if (verbose): print(\"embedding_library[feature_name](raw_idx):\",emb,\"\\n\")\n",
    "#     subvector = torch.Tensor(emb)\n",
    "#     if (verbose): print(\"subvector:\",subvector)\n",
    "    \n",
    "#     return subvector\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "posted-earth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Test:\n",
      "\tSanple feature: cat3\n",
      "\tSanple category: H\n",
      "\tSanple category embedding: tensor([[ 0.4784,  0.5086, -0.3467]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "# # Confirm function structure\n",
    "test_cat_dict,test_embeddings = BuildEmbedlibrary(train.select_dtypes('object'))\n",
    "test_subvec = CatToSubvector(target_cat_keys_sample,target_cat_name,test_cat_dict,test_embeddings)\n",
    "\n",
    "print(\"Embedding Test:\")\n",
    "print(\"\\tSanple feature:\",target_cat_name)\n",
    "print(\"\\tSanple category:\",target_cat_keys_sample)\n",
    "print(\"\\tSanple category embedding:\",test_subvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cordless-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data\n",
    "\n",
    "#define dataset\n",
    "class ClaimsDataset(Dataset):\n",
    "    def __init__(self, csv_path,labelled=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            raw_data (dataframe): Dataframe with raw featurres and labels.\n",
    "        \"\"\"\n",
    "        file_check_target = \"train\" if (labelled) else \"test\"\n",
    "        \n",
    "#         print(\"{}_set_x.pt\".format(file_check_target))\n",
    "#         print(\"{}_set_y.pt\".format(file_check_target))\n",
    "        \n",
    "        if(exists( \"{}_set_x.pt\".format(file_check_target) ) and exists( \"{}_set_y.pt\".format(file_check_target) )):\n",
    "            self.data = torch.load(\"{}_set_x.pt\".format(file_check_target))\n",
    "            self.target = torch.load(\"{}_set_y.pt\".format(file_check_target))\n",
    "        else:\n",
    "            # Read data\n",
    "            raw_data = pd.read_csv(csv_path)\n",
    "\n",
    "    #         self.l = len(raw_data)\n",
    "            # Separate future parameters/labels\n",
    "            labels = raw_data.pop('target') if labelled else torch.tensor([], dtype=torch.long)\n",
    "            categorical_features = raw_data.select_dtypes(include='object')\n",
    "            noncategorical_features = raw_data.select_dtypes(exclude='object')\n",
    "\n",
    "            # Build feature embeddings\n",
    "            categoricals,embeddings = BuildEmbedlibrary(categorical_features)\n",
    "\n",
    "            # Convert embeddings to parameters\n",
    "            subvects = DataFrame()\n",
    "    #         for row in categorical_features.values:\n",
    "    #             subsubvects = []\n",
    "    #             for v,c in zip(row,categorical_features.columns):\n",
    "    #                 subsubvects.append(CatToSubvector(v,c,self.categoricals,self.embeddings))\n",
    "    # #             [print(\"subsubvect size:\",ssv.size()) for ssv in subsubvects]\n",
    "    #             subvects.append(torch.cat(subsubvects,1))\n",
    "            subsubvects = []\n",
    "\n",
    "            for col in categorical_features.columns:\n",
    "                print(\"Converting collection of categories, {}, to collection of embeddings...\".format(col))\n",
    "                cat_col = (categorical_features[col]).tolist()\n",
    "    #             print(\"cat_col:\",cat_col,\"\\n\")\n",
    "    #             cat_emb = cat_col\n",
    "    #             cat_emb = cat_col.apply(lambda x: CatToSubvector(x,col,self.categoricals,self.embeddings,True))\n",
    "    #             if (i%2):# == 0 and i!=0):\n",
    "    #                 print(\"i:\",i)\n",
    "    #                 cat_emb = cat_col.apply(lambda x: CatToSubvector(x,col,self.categoricals,self.embeddings,True))\n",
    "    #                 print(\"cat_emb:\",cat_emb,\"\\n\")\n",
    "    #             else:\n",
    "    #                 cat_emb = cat_col.apply(lambda x: CatToSubvector(x,col,self.categoricals,self.embeddings,False))\n",
    "                cat_embs = CatToSubvector(cat_col[0],col,categoricals,embeddings,False)\n",
    "                for x in cat_col[1:]:\n",
    "                    new_emb = CatToSubvector(x,col,categoricals,embeddings,False)\n",
    "                    cat_embs = torch.cat((cat_embs,new_emb))\n",
    "    #             cat_emb = [CatToSubvector(x,col,self.categoricals,self.embeddings) for x in cat_col]\n",
    "    #             print(col,\"cat_embs.shape:\",cat_embs.shape,\"\\n\")\n",
    "    #             cat_emb = torch.cat(tuple(cat_emb))\n",
    "    #             print(\"type(cat_emb[-10]):\",type(cat_emb[-10]),\"\\n\")\n",
    "    #             print(\"cat_emb[-10]:\",cat_emb[-10],\"\\n\")\n",
    "                subsubvects.append(cat_embs)\n",
    "\n",
    "    #         print(\"tuple(subsubvects):\",tuple(subsubvects),\"\\n\")\n",
    "            subvects = torch.cat(tuple(subsubvects),1)\n",
    "    #         print(\"subvects[1]:\",subvects[1],\"\\n\")\n",
    "    #         print(\"subvects.shape:\",subvects.shape,\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "            # copy the data \n",
    "            df_min_max_scaled = noncategorical_features.copy()\n",
    "\n",
    "            # apply normalization techniques by Column 1 \n",
    "            for col in df_min_max_scaled.columns:\n",
    "                df_min_max_scaled[col] = (df_min_max_scaled[col] - df_min_max_scaled[col].min()) /\\\n",
    "                    (df_min_max_scaled[col].max() - df_min_max_scaled[col].min())\n",
    "\n",
    "    #         noncat_mean = noncategorical_features.mean(1)\n",
    "    #         noncat_std = noncategorical_features.std(1)\n",
    "\n",
    "\n",
    "            self.data = torch.cat((\n",
    "                subvects,\n",
    "    #             torch.tensor(noncategorical_features.values)\n",
    "                torch.tensor(df_min_max_scaled.values)\n",
    "            ),1)\n",
    "            torch.save(self.data,\"{}_set_x.pt\".format(file_check_target))\n",
    "\n",
    "    #         print(\"labels:\",labels)\n",
    "    #         print(\"labels.tolist():\",labels.tolist())\n",
    "            self.target = torch.tensor(labels.tolist(), dtype=torch.int)\n",
    "            torch.save(self.target,\"{}_set_y.pt\".format(file_check_target))\n",
    "    #         print(\"self.target:\",self.target)\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "            \n",
    "        return x,y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "binding-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO add functionality for unlabbeled data\n",
    "def LoadData(bs=4,target='train'):\n",
    "    sets = {\n",
    "        'train':None,\n",
    "        'test':None,\n",
    "    }\n",
    "    train_loader,test_loader = None,None\n",
    "#     bs = 2*batch_size_oom\n",
    "    \n",
    "    if(target=='train'):\n",
    "        sets['train'] = ClaimsDataset('./train.csv',labelled=True)\n",
    "        train_loader = DataLoader(sets['train'],batch_size=bs,shuffle=True)\n",
    "    elif(target=='test'):\n",
    "        sets['test'] = ClaimsDataset('./test.csv')\n",
    "        test_loader = DataLoader(sets['test'],batch_size=bs,shuffle=True)\n",
    "    elif(target=='both'):\n",
    "        sets['train'],sets['test'] = ClaimsDataset('./train.csv',labelled=True),ClaimsDataset('./test.csv')\n",
    "        train_loader,test_loader = DataLoader(sets['train'],batch_size=bs,shuffle=True),DataLoader(sets['test'],batch_size=bs,shuffle=True)\n",
    "    else:\n",
    "        print(\"Invalid target name supplied. Returning None.\")\n",
    "    \n",
    "#     train_set,test_set = ClaimsDataset('./train.csv',labelled=True),ClaimsDataset('./test.csv')\n",
    "#     train_loader,test_loader = DataLoader(claimset,batch_size=bs,shuffle=True)\n",
    "#     train_loader,test_loader = DataLoader(train_set,batch_size=bs,shuffle=True),DataLoader(test_set,batch_size=bs,shuffle=True)\n",
    "    \n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "balanced-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "x: tensor([[ 0.2649,  1.0084,  0.2915, -0.3645, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.9232,  1.3783, -1.3629,  0.3822, -1.6283,  1.6023, -0.2877, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653,  0.1242, -0.0285,  1.9937,  1.6600,\n",
      "         -0.0452,  1.1286,  0.0551,  1.2681,  0.2953, -2.3460, -1.5527, -0.7345,\n",
      "          0.9506, -0.1658, -0.3651,  0.2640,  1.1973,  0.2725,  0.4662,  0.4327,\n",
      "         -0.0588,  0.3551, -0.1603, -0.3965, -1.4530, -0.6877,  0.0445, -2.0459,\n",
      "         -1.0834,  1.5678, -0.2785, -0.3143, -0.4242, -0.3278,  0.1753,  0.1523,\n",
      "         -0.3435, -0.6364,  0.9847,  0.8394,  0.0222, -1.2007,  0.9515, -2.2034,\n",
      "          1.5220, -1.8895,  1.1652,  0.7467,  0.5699,  0.8305,  0.8750,  0.1078,\n",
      "          0.7332,  0.8834,  0.5869,  0.3435,  0.6048,  0.1395,  0.4699],\n",
      "        [ 0.2649, -0.5148, -1.7510, -0.1913, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.7208, -0.0920, -0.8047, -0.0244,  1.0849,  1.1587,  0.2736, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653, -0.1675, -1.8384,  0.5200,  0.0078,\n",
      "         -1.0783,  2.3698,  0.0919, -0.1375, -1.3059, -1.1732,  0.4796, -0.5581,\n",
      "         -0.0820, -0.3022, -0.0977,  0.1371, -0.3178, -0.5599, -1.3897,  0.2128,\n",
      "          0.1067,  0.2569,  1.3094, -1.2453,  1.0769, -2.0162, -0.0574,  1.2622,\n",
      "          1.5580,  1.0664,  0.6092, -0.0525, -0.4026, -0.3575, -0.2256,  0.1523,\n",
      "         -0.3435, -0.6364,  0.9847,  0.0473,  0.7524,  0.3026, -1.2232,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.8545,  0.8866,  0.7346,  0.8339,  0.9419,\n",
      "          0.8902,  0.5157,  0.2476,  0.8602,  0.5232,  0.7741,  0.9049],\n",
      "        [-0.6965, -0.8346,  0.6561, -1.1675, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.9232,  1.3783, -1.3629, -0.0244,  1.0849,  1.1587,  0.2736, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653, -0.5272,  0.6662, -0.7860, -1.6878,\n",
      "         -0.8778,  1.1318, -0.8581,  0.7976, -0.4767,  0.6723,  0.6291, -0.0533,\n",
      "         -1.0135, -0.0162, -0.0977,  0.1371, -0.3178, -0.5599, -0.9152,  1.2662,\n",
      "          0.5085, -1.2836, -0.7129, -0.3921,  2.1114, -0.7057, -0.3258,  0.5305,\n",
      "          1.3985,  0.3431, -0.2098,  1.2416, -0.2609,  0.9596, -0.6457,  0.1523,\n",
      "         -0.3435, -0.6364,  1.2252,  0.0473,  0.7524,  0.3026, -1.2232,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.8869,  0.6281,  0.3887,  0.4020,  0.7122,\n",
      "          0.6363,  0.6649,  0.2376,  0.4624,  0.3120,  0.4252,  0.6188],\n",
      "        [ 0.2649, -0.5148, -1.7510, -0.1913, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.8375,  0.0085,  0.2313, -0.6669,  0.0536,  0.3133,  1.0023, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "         -0.0983,  0.1860, -0.6573, -0.3877,  0.5221, -1.0674,  0.2260,  0.1850,\n",
      "          1.2074, -0.5868, -0.4133, -0.0640, -0.5276, -0.7651,  1.7557, -0.0783,\n",
      "          1.2237, -2.0273, -0.3651,  0.2640,  1.1973,  0.2725, -0.1238, -0.0809,\n",
      "         -0.6064,  0.0767, -0.5847,  0.7327,  0.6849, -1.4233,  1.4009, -3.0443,\n",
      "         -0.6657, -0.1379,  0.1206, -0.7897, -0.3627,  0.3122, -0.6486,  0.1523,\n",
      "         -0.3435, -0.6364,  1.2252,  0.8394,  0.0222, -1.2007,  0.9515, -2.2034,\n",
      "          1.5220, -1.8895,  1.1652,  0.1782,  0.6588,  0.4911,  0.3622,  0.3665,\n",
      "          0.1266,  0.8039,  0.2270,  0.4169,  0.3489,  0.2085,  0.5096]],\n",
      "       dtype=torch.float64, grad_fn=<StackBackward>)\n",
      "y: tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "i: 25000\n",
      "x: tensor([[-0.6965,  1.3686,  1.4191, -0.5208, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.9232,  1.3783, -1.3629, -0.0244,  1.0849,  1.1587,  0.2736, -0.3439,\n",
      "          0.7384,  1.5573, -0.8074, -1.6828, -0.5794,  0.5368, -0.3502,  1.4539,\n",
      "         -0.4173,  1.4365, -0.7526,  1.3592,  2.1537, -0.5172,  0.5809,  0.0650,\n",
      "          0.8990,  0.3609, -0.6573,  1.0864, -0.1155,  0.1700,  0.1603,  0.5019,\n",
      "         -1.6318, -1.0163, -1.6874, -0.3256,  1.6845,  0.9046, -0.5064,  0.8170,\n",
      "         -1.0867,  0.1812,  0.2936, -0.4258,  0.6043,  1.6964,  1.2921,  0.3968,\n",
      "         -1.2478,  0.9865,  0.3362, -0.3667,  0.4215, -0.4883, -0.5472,  0.1523,\n",
      "         -0.3435, -0.6364,  1.2252,  0.8394,  0.0222,  0.3026, -1.2232,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.1905,  0.7427,  0.2850,  0.2338,  0.2090,\n",
      "          0.6549,  0.6660,  0.5926,  0.2819,  0.4283,  0.7697,  0.2502],\n",
      "        [ 0.2649,  1.2907, -0.2222, -0.6173, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.8375,  0.0085,  0.2313, -0.0244,  1.0849,  1.1587,  0.2736,  2.5716,\n",
      "          0.6523, -0.1905, -0.5340, -1.2295,  1.6530,  1.3033, -0.9646, -1.4434,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653, -0.1811,  0.8460,  1.0334,  0.0071,\n",
      "          2.4760,  0.3610,  0.5643, -0.0472, -0.3175, -0.8798, -0.1673, -1.4027,\n",
      "          0.9012, -0.6318, -0.3651,  0.2640,  1.1973,  0.2725,  0.1571, -0.3610,\n",
      "         -0.4050,  0.7410, -0.0793,  2.2512, -1.6049,  1.2520, -1.5445, -1.0243,\n",
      "          0.5981,  0.1767, -0.3489,  0.4948, -0.2774,  0.6555, -0.9032,  0.1523,\n",
      "         -0.3435, -0.6364,  1.2252,  0.0473,  0.7524,  0.3026, -1.2232,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.2678,  0.3287,  0.1532,  0.1747,  0.2069,\n",
      "          0.9268,  0.5876,  0.5043,  0.1299,  0.2425,  0.3765,  0.3162],\n",
      "        [ 0.2649, -1.1144, -0.5520, -0.2157, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.8375,  0.0085,  0.2313, -0.0244,  1.0849,  1.1587,  0.2736,  1.4776,\n",
      "         -0.1809, -0.8184, -0.2385,  1.5844, -1.8904, -1.0936,  0.0415, -0.6567,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653, -0.1811,  0.8460,  1.0334,  0.0071,\n",
      "          2.4760,  0.3610,  0.5643, -1.5780,  2.7057,  2.1644,  0.7670,  0.2018,\n",
      "         -0.1768, -1.3309, -0.8834, -0.3064, -0.2071, -1.4955, -0.0269, -1.3850,\n",
      "          0.7297,  0.1987, -0.0877,  0.6307, -0.1725,  0.3917, -1.6876,  1.0670,\n",
      "          0.6703, -0.0312, -0.0862,  0.8054, -0.6882,  0.3120,  0.3955,  0.1523,\n",
      "         -1.2131, -0.6364,  0.9847,  0.0473,  0.7524,  0.3026, -1.2232,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.6625,  0.3432,  0.1661,  0.0416,  0.6171,\n",
      "          0.9390,  0.7373,  0.5783,  0.1160,  0.2341,  0.3836,  0.1948],\n",
      "        [ 0.2649,  0.4397, -0.1099, -0.5398, -0.4913, -2.4970, -1.6142, -0.5667,\n",
      "          0.9232,  1.3783, -1.3629, -0.0244,  1.0849,  1.1587,  0.2736,  2.5716,\n",
      "          0.6523, -0.1905, -0.5340, -1.2295,  1.6530,  1.3033, -0.9646, -1.4434,\n",
      "          0.6111, -0.4715, -1.4321,  0.0653,  0.5221, -1.0674,  0.2260,  0.1850,\n",
      "          1.2074, -0.5868, -0.4133,  0.1764, -0.7283, -0.3273,  0.2224,  1.0174,\n",
      "         -0.8242, -1.4255, -0.3651,  0.2640,  1.1973,  0.2725, -0.6281,  0.4346,\n",
      "          0.6342,  1.6478,  2.0871,  0.7236, -0.6318,  1.1329,  0.5738,  0.7874,\n",
      "         -0.4283, -0.9146, -0.1673, -0.4464,  1.4584,  0.5198, -0.4802,  0.1523,\n",
      "         -0.3435, -0.6364,  0.9847,  0.8394,  0.0222, -1.2007,  0.9515,  1.3522,\n",
      "          0.7104, -1.8895,  1.1652,  0.4178,  0.6377,  0.3493,  0.4046,  0.3432,\n",
      "          0.0994,  0.2011,  0.1918,  0.4655,  0.3199,  0.2417,  0.4891]],\n",
      "       dtype=torch.float64, grad_fn=<StackBackward>)\n",
      "y: tensor([1, 0, 0, 0], dtype=torch.int32)\n",
      "i: 50000\n",
      "x: tensor([[ 2.6494e-01, -5.1479e-01, -1.7510e+00, -1.9128e-01, -4.9128e-01,\n",
      "         -2.4970e+00, -1.6142e+00, -5.6671e-01,  8.3750e-01,  8.4645e-03,\n",
      "          2.3129e-01,  7.7415e-02,  1.1098e+00,  1.1245e+00, -5.8459e-01,\n",
      "         -3.4389e-01,  7.3836e-01,  1.5573e+00, -8.0743e-01, -1.6828e+00,\n",
      "         -5.7936e-01,  5.3684e-01, -3.5020e-01,  1.4539e+00,  6.1113e-01,\n",
      "         -4.7155e-01, -1.4321e+00,  6.5348e-02,  1.2422e-01, -2.8475e-02,\n",
      "          1.9937e+00,  1.6600e+00, -4.5159e-02,  1.1286e+00,  5.5090e-02,\n",
      "          1.2681e+00,  2.9534e-01, -2.3460e+00, -1.5527e+00, -7.3447e-01,\n",
      "          9.5057e-01, -1.6582e-01, -1.1666e+00,  1.0281e+00,  1.7278e+00,\n",
      "          2.8744e+00,  2.0671e-01, -1.8694e-01, -8.2988e-01, -7.0855e-02,\n",
      "          1.1714e+00, -9.6537e-01, -2.9793e-02,  1.1052e+00, -1.8363e+00,\n",
      "          3.9996e-01, -2.7701e-01, -5.0626e-01, -1.3368e+00,  8.8220e-01,\n",
      "         -7.9429e-01, -1.2347e+00, -4.4776e-01,  1.5232e-01, -1.2131e+00,\n",
      "         -6.3641e-01,  9.8467e-01,  4.7257e-02,  7.5238e-01,  3.0255e-01,\n",
      "         -1.2232e+00,  1.3522e+00,  7.1042e-01, -1.8895e+00,  1.1652e+00,\n",
      "          9.3388e-01,  5.2284e-01,  5.3197e-01,  3.8619e-01,  2.4122e-01,\n",
      "          7.2780e-01,  3.8594e-01,  6.1611e-01,  3.9779e-01,  3.0032e-01,\n",
      "          4.1970e-02,  3.3935e-01],\n",
      "        [ 2.6494e-01,  1.0084e+00,  2.9148e-01, -3.6455e-01,  2.3099e+00,\n",
      "          6.3913e-01,  7.0056e-01, -2.4055e+00,  8.3750e-01,  8.4645e-03,\n",
      "          2.3129e-01,  8.3143e-01,  7.0703e-01, -2.7223e-01,  4.7644e-01,\n",
      "         -3.4389e-01,  7.3836e-01,  1.5573e+00, -8.0743e-01, -1.6828e+00,\n",
      "         -5.7936e-01,  5.3684e-01, -3.5020e-01,  1.4539e+00,  6.1113e-01,\n",
      "         -4.7155e-01, -1.4321e+00,  6.5348e-02, -3.6864e-01,  5.3418e-01,\n",
      "         -9.5334e-01, -7.7301e-01, -9.9488e-01,  5.1280e-01,  8.1866e-01,\n",
      "         -7.9135e-01, -1.3082e+00,  7.1919e-01,  5.6135e-01,  1.0560e-01,\n",
      "          1.5329e+00, -4.8015e-01, -3.6509e-01,  2.6401e-01,  1.1973e+00,\n",
      "          2.7247e-01, -1.1540e+00, -3.0705e-01, -5.8400e-01,  1.5067e+00,\n",
      "         -9.0691e-01,  1.0720e+00,  1.4963e+00, -1.0942e-01,  3.0496e-01,\n",
      "          7.2150e-01, -3.0218e-01,  2.0827e+00,  1.3972e-01, -4.9622e-02,\n",
      "         -2.1116e-01, -7.0525e-01, -1.6635e+00, -4.4934e-01, -3.4354e-01,\n",
      "         -6.3641e-01,  9.8467e-01,  4.7257e-02,  7.5238e-01,  3.0255e-01,\n",
      "         -1.2232e+00,  1.3522e+00,  7.1042e-01, -1.8895e+00,  1.1652e+00,\n",
      "          5.0962e-01,  5.5503e-01,  2.6377e-01,  2.9187e-01,  3.4064e-01,\n",
      "          7.7779e-02,  5.8967e-01,  5.6305e-01,  2.8238e-01,  2.9940e-01,\n",
      "          3.7300e-01,  3.9585e-01],\n",
      "        [ 2.6494e-01, -9.0119e-01, -5.7244e-01, -2.0111e+00, -4.9128e-01,\n",
      "         -2.4970e+00, -1.6142e+00, -5.6671e-01,  9.2321e-01,  1.3783e+00,\n",
      "         -1.3629e+00,  3.8216e-01, -1.6283e+00,  1.6023e+00, -2.8774e-01,\n",
      "         -3.4389e-01,  7.3836e-01,  1.5573e+00, -8.0743e-01, -1.6828e+00,\n",
      "         -5.7936e-01,  5.3684e-01, -3.5020e-01,  1.4539e+00,  6.1113e-01,\n",
      "         -4.7155e-01, -1.4321e+00,  6.5348e-02,  1.5251e-02,  2.1411e+00,\n",
      "         -6.9370e-01, -7.7048e-01, -6.8245e-01, -1.7001e+00, -4.1910e-01,\n",
      "         -1.8328e+00,  4.1460e-01, -2.7054e-01,  1.6995e-01, -4.9336e-02,\n",
      "         -3.8915e-02,  1.8762e+00, -3.6509e-01,  2.6401e-01,  1.1973e+00,\n",
      "          2.7247e-01, -9.1629e-01,  1.0375e+00,  9.9691e-01, -1.7643e+00,\n",
      "          2.5456e-01, -8.2076e-01,  3.8430e-01,  3.1450e-01, -1.4585e+00,\n",
      "         -4.0835e-01,  1.4220e+00,  6.2012e-01,  4.4140e-01,  6.4828e-01,\n",
      "          1.4203e+00, -5.3343e-02, -3.1699e-01,  1.5232e-01, -3.4354e-01,\n",
      "         -6.3641e-01,  1.2252e+00,  9.6520e-01,  1.1646e+00, -1.2007e+00,\n",
      "          9.5150e-01, -2.2034e+00,  1.5220e+00, -1.8895e+00,  1.1652e+00,\n",
      "          4.8789e-01,  4.1986e-01,  7.2443e-01,  7.3698e-01,  2.9744e-01,\n",
      "          1.8210e-01,  9.2855e-01,  8.9493e-01,  4.8459e-01,  6.3807e-01,\n",
      "          4.2212e-01,  3.9247e-01],\n",
      "        [ 2.6494e-01, -9.0119e-01, -5.7244e-01, -2.0111e+00, -2.9678e-01,\n",
      "          1.4453e+00, -1.3296e+00,  1.5202e+00,  9.2321e-01,  1.3783e+00,\n",
      "         -1.3629e+00,  1.4823e+00, -1.0652e-01,  8.9024e-01,  5.5748e-01,\n",
      "         -3.4389e-01,  7.3836e-01,  1.5573e+00, -8.0743e-01, -1.6828e+00,\n",
      "         -5.7936e-01,  5.3684e-01, -3.5020e-01,  1.4539e+00,  6.1113e-01,\n",
      "         -4.7155e-01, -1.4321e+00,  6.5348e-02, -5.8198e-01,  3.7465e-03,\n",
      "         -1.0068e+00,  6.3175e-01,  8.4088e-01,  3.7349e-01,  7.2984e-01,\n",
      "         -1.5353e+00, -2.1385e-04,  7.4967e-01, -1.8420e+00,  9.8551e-03,\n",
      "         -9.7503e-01, -1.3641e+00, -3.6509e-01,  2.6401e-01,  1.1973e+00,\n",
      "          2.7247e-01, -2.8366e-01,  1.7474e-01,  2.1335e+00, -3.4963e-01,\n",
      "          8.8885e-01,  1.9033e-01,  2.7112e-01,  3.7319e-01,  3.2880e-01,\n",
      "         -1.5966e+00,  1.0062e+00, -2.3646e-01,  5.3260e-01, -1.4584e+00,\n",
      "          4.2822e-01, -1.4765e+00, -2.7724e-01, -4.4934e-01, -3.4354e-01,\n",
      "         -4.7008e-01,  1.2252e+00,  4.7257e-02,  7.5238e-01, -1.2007e+00,\n",
      "          9.5150e-01,  6.3535e-01, -9.9917e-01,  2.7767e-02,  1.7245e+00,\n",
      "          9.9117e-01,  5.1237e-01,  3.9149e-01,  4.5340e-01,  6.9893e-01,\n",
      "          7.8026e-01,  8.0655e-01,  6.3629e-01,  3.1469e-01,  4.4942e-01,\n",
      "          1.7617e-01,  3.5062e-01]], dtype=torch.float64,\n",
      "       grad_fn=<StackBackward>)\n",
      "y: tensor([0, 0, 1, 1], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "trainloader,testloader = LoadData()\n",
    "# # print(\"cd.categoricals:\",cd.categoricals,\"\\n\",\"cd.embeddings:\",cd.embeddings,\"\\n\",\"cd.vectors.shape:\",cd.vectors.shape)\n",
    "i = 0\n",
    "for x,y in trainloader:\n",
    "    if not i%25000:\n",
    "        print(\"i:\",i)\n",
    "        print(\"x:\",x)\n",
    "        print(\"y:\",y)\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-calendar",
   "metadata": {},
   "source": [
    "# train_set_x = (trainloader.dataset)[:][0]\n",
    "r = torch.load('train_set_x.pt')\n",
    "print(r[200000:200004])\n",
    "# train_set_y = (trainloader.dataset)[:][1]\n",
    "e = torch.load('train_set_y.pt')\n",
    "print(e[200000:200004])\n",
    "# numpy.save('data/train_set_x.pt',(trainloader.dataset)[:][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-appreciation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define model search space\n",
    "# import torch.nn.functional as F\n",
    "# import nni.retiarii.nn.pytorch as nn\n",
    "# from nni.retiarii import model_wrapper\n",
    "\n",
    "class FullConn(nn.Module):\n",
    "    def __init__(self,signal):\n",
    "        out_features = nn.ValueChoice(range(2**10+1))\n",
    "        num_groups = nn.ValueChoice(range(2, o_f/2+1))\n",
    "        self.linear = nn.Linear(\n",
    "            in_features = signal.shape[-1],\n",
    "            out_features = out_features\n",
    "        )\n",
    "        self.norm = nn.GroupNorm(\n",
    "            num_groups = num_groups,\n",
    "            num_channels = o_f\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "class Drop(nn.Module):\n",
    "    def __init__(self):\n",
    "        p = nn.ValueChoice(range(0.5,0.91,0.01))\n",
    "        self.dropout = nn.Dropout(p = p)\n",
    "    def forward(self, x):\n",
    "        return self.dropout(x)\n",
    "\n",
    "@model_wrapper # flag outermost Pytorch module\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        signal_tensor = torch.load('train_set_x.pt')\n",
    "        stack = OrderedDict()\n",
    "        layer_count = nn.ValueChoice(range(2,2**10+1))\n",
    "        signal = signal_tensor.shape[-1]\n",
    "        for i in range(layer_count):\n",
    "            index = \"{}\".format(i)\n",
    "            stack[index] = FullConn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "useful-extent",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def search_training_hyperparameters():\n",
    "    lr = {\n",
    "        \"name\":\"learning rate {10^(-⌊x⌋)\",\n",
    "        \"bounds\":[x for x in range(1,4)]\n",
    "    }\n",
    "    batch_size = {\n",
    "        \"name\":\"batch size {2^⌊x⌋}\",\n",
    "        \"bounds\":[x for x in range(6,9)]\n",
    "    }\n",
    "    epochs = {\n",
    "        \"name\":\"epochs {10⌊x⌋}\",\n",
    "        \"bounds\":[x for x in range(2,6)]\n",
    "    }\n",
    "    \n",
    "    config_space = CS.ConfigurationSpace()\n",
    "    config_space_dict,config_space_ray = {},{}\n",
    "    \n",
    "    #start ConfigSpace API\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.UniformFloatHyperparameter(\n",
    "            lr[\"name\"],\n",
    "            lr[\"bounds\"][0],\n",
    "            lr[\"bounds\"][-1],\n",
    "            log=True\n",
    "        ))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(\n",
    "            batch_size[\"name\"], \n",
    "            batch_size[\"bounds\"]\n",
    "        ))\n",
    "    config_space.add_hyperparameter(\n",
    "        CS.CategoricalHyperparameter(\n",
    "            epochs[\"name\"], \n",
    "            epochs[\"bounds\"]\n",
    "        ))\n",
    "    \n",
    "    #start Ray Search Space API\n",
    "    config_space_ray[lr[\"name\"]] = tune.loguniform(lr[\"bounds\"][0],lr[\"bounds\"][-1])\n",
    "    config_space_ray[batch_size[\"name\"]] = tune.choice(batch_size[\"bounds\"])\n",
    "    config_space_ray[epochs[\"name\"]] = tune.choice(categories=epochs[\"bounds\"])\n",
    "    \n",
    "    #start Dragonfly Search Space API\n",
    "    param_list = [\n",
    "        {\n",
    "            \"name\": lr[\"name\"], \n",
    "            \"type\": \"float\", \n",
    "            \"min\": lr[\"bounds\"][0], \n",
    "            \"max\": lr[\"bounds\"][-1]\n",
    "        },\n",
    "        {\n",
    "            \"name\": batch_size[\"name\"], \n",
    "            \"type\": \"discrete_numeric\", \n",
    "            \"items\": \":\".join([str(2**x) for x in batch_size[\"bounds\"]])\n",
    "        },\n",
    "        {\n",
    "            \"name\": epochs[\"name\"], \n",
    "            \"type\": \"discrete_numeric\", \n",
    "            \"items\": \":\".join([str(10*x) for x in epochs[\"bounds\"]])\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    #start BayesOpt Search Space API\n",
    "    config_space_dict[lr[\"name\"]] = tune.uniform(lr[\"bounds\"][0],lr[\"bounds\"][-1])\n",
    "    config_space_dict[batch_size[\"name\"]] = tune.uniform(lower=batch_size[\"bounds\"][0], upper=batch_size[\"bounds\"][-1])\n",
    "    config_space_dict[epochs[\"name\"]] = tune.uniform(lower=epochs[\"bounds\"][0], upper=epochs[\"bounds\"][-1])\n",
    "    \n",
    "    #start Discrete Search Search Space API\n",
    "    param_dict = {p[\"name\"]:p[\"bounds\"] for p in [lr,batch_size,epochs]}\n",
    "    \n",
    "    #start PB2 Space API\n",
    "    min_max_param_dict = {p[\"name\"]:[p[\"bounds\"][0], p[\"bounds\"][-1]] for p in [lr,batch_size,epochs]}\n",
    "    \n",
    "    return config_space_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
